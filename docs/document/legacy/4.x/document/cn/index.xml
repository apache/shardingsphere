<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ShardingSphere</title>
    <link>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/</link>
    <description>Recent content on ShardingSphere</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    
	<atom:link href="https://shardingsphere.apache.org/document/legacy/4.x/document/cn/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Java配置</title>
      <link>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/manual/sharding-jdbc/configuration/config-java/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/manual/sharding-jdbc/configuration/config-java/</guid>
      <description>配置示例 数据分片 以下配置中DataSourceUtil的实现为DataSourceUtil，ModuloShardingTableAlgorithm 类需用户自定义实现，详细例子 ModuloShardingTableAlgorithm
DataSource getShardingDataSource() throws SQLException { ShardingRuleConfiguration shardingRuleConfig = new ShardingRuleConfiguration(); shardingRuleConfig.getTableRuleConfigs().add(getOrderTableRuleConfiguration()); shardingRuleConfig.getTableRuleConfigs().add(getOrderItemTableRuleConfiguration()); shardingRuleConfig.getBindingTableGroups().add(&amp;quot;t_order, t_order_item&amp;quot;); shardingRuleConfig.getBroadcastTables().add(&amp;quot;t_config&amp;quot;); shardingRuleConfig.setDefaultDatabaseShardingStrategyConfig(new InlineShardingStrategyConfiguration(&amp;quot;user_id&amp;quot;, &amp;quot;ds${user_id % 2}&amp;quot;)); shardingRuleConfig.setDefaultTableShardingStrategyConfig(new StandardShardingStrategyConfiguration(&amp;quot;order_id&amp;quot;, new ModuloShardingTableAlgorithm())); return ShardingDataSourceFactory.createDataSource(createDataSourceMap(), shardingRuleConfig, new Properties()); } private static KeyGeneratorConfiguration getKeyGeneratorConfiguration() { KeyGeneratorConfiguration result = new KeyGeneratorConfiguration(&amp;quot;SNOWFLAKE&amp;quot;, &amp;quot;order_id&amp;quot;); return result; } TableRuleConfiguration getOrderTableRuleConfiguration() { TableRuleConfiguration result = new TableRuleConfiguration(&amp;quot;t_order&amp;quot;, &amp;quot;ds${0..1}.t_order${0..1}&amp;quot;); result.setKeyGeneratorConfig(getKeyGeneratorConfiguration()); return result; } TableRuleConfiguration getOrderItemTableRuleConfiguration() { TableRuleConfiguration result = new TableRuleConfiguration(&amp;quot;t_order_item&amp;quot;, &amp;quot;ds${0.</description>
    </item>
    
    <item>
      <title>SQL</title>
      <link>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/sharding/concept/sql/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/sharding/concept/sql/</guid>
      <description>逻辑表 水平拆分的数据库（表）的相同逻辑和数据结构表的总称。例：订单数据根据主键尾数拆分为10张表，分别是t_order_0到t_order_9，他们的逻辑表名为t_order。
真实表 在分片的数据库中真实存在的物理表。即上个示例中的t_order_0到t_order_9。
数据节点 数据分片的最小单元。由数据源名称和数据表组成，例：ds_0.t_order_0。
绑定表 指分片规则一致的主表和子表。例如：t_order表和t_order_item表，均按照order_id分片，则此两张表互为绑定表关系。绑定表之间的多表关联查询不会出现笛卡尔积关联，关联查询效率将大大提升。举例说明，如果SQL为：
SELECT i.* FROM t_order o JOIN t_order_item i ON o.order_id=i.order_id WHERE o.order_id in (10, 11);  在不配置绑定表关系时，假设分片键order_id将数值10路由至第0片，将数值11路由至第1片，那么路由后的SQL应该为4条，它们呈现为笛卡尔积：
SELECT i.* FROM t_order_0 o JOIN t_order_item_0 i ON o.order_id=i.order_id WHERE o.order_id in (10, 11); SELECT i.* FROM t_order_0 o JOIN t_order_item_1 i ON o.order_id=i.order_id WHERE o.order_id in (10, 11); SELECT i.* FROM t_order_1 o JOIN t_order_item_0 i ON o.order_id=i.order_id WHERE o.order_id in (10, 11); SELECT i.</description>
    </item>
    
    <item>
      <title>SQL</title>
      <link>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/sharding/use-norms/sql/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/sharding/use-norms/sql/</guid>
      <description>由于SQL语法灵活复杂，分布式数据库和单机数据库的查询场景又不完全相同，难免有和单机数据库不兼容的SQL出现。
本文详细罗列出已明确可支持的SQL种类以及已明确不支持的SQL种类，尽量让使用者避免踩坑。
其中必然有未涉及到的SQL欢迎补充，未支持的SQL也尽量会在未来的版本中支持。
支持项 路由至单数据节点  100%全兼容（目前仅MySQL，其他数据库完善中）。  路由至多数据节点 全面支持DML、DDL、DCL、TCL和部分DAL。支持分页、去重、排序、分组、聚合、关联查询（不支持跨库关联）。以下用最为复杂的DML举例：
 SELECT主语句  SELECT select_expr [, select_expr ...] FROM table_reference [, table_reference ...] [WHERE predicates] [GROUP BY {col_name | position} [ASC | DESC], ...] [ORDER BY {col_name | position} [ASC | DESC], ...] [LIMIT {[offset,] row_count | row_count OFFSET offset}]   select_expr  * | [DISTINCT] COLUMN_NAME [AS] [alias] | (MAX | MIN | SUM | AVG)(COLUMN_NAME | alias) [AS] [alias] | COUNT(* | COLUMN_NAME | alias) [AS] [alias]   table_reference  tbl_name [AS] alias] [index_hint_list] | table_reference ([INNER] | {LEFT|RIGHT} [OUTER]) JOIN table_factor [JOIN ON conditional_expr | USING (column_list)]  不支持项 路由至多数据节点 不支持CASE WHEN、HAVING、UNION (ALL)，有限支持子查询。</description>
    </item>
    
    <item>
      <title>SQL测试用例</title>
      <link>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/test-engine/sql-case/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/test-engine/sql-case/</guid>
      <description>目标 SQL测试用例的代码位于 sharding-sql-test 模块下。该测试用例的作用主要有两个：
 通过单元测试，测试通配符的替换以及 SQLCasesLoader 的稳定性。 将SQL测试用例中 resources 下定义的所有 SQL 共享给其他项目。  待测试的 SQL 存放在 /sharding-sql-test/src/main/resources/sql/sharding/SQL-TYPE/*.xml文件中。例如：
&amp;lt;sql-cases&amp;gt; &amp;lt;sql-case id=&amp;quot;select_constant_without_table&amp;quot; value=&amp;quot;SELECT 1 as a&amp;quot; /&amp;gt; &amp;lt;sql-case id=&amp;quot;select_with_same_table_name_and_alias&amp;quot; value=&amp;quot;SELECT t_order.* FROM t_order t_order WHERE user_id = ? AND order_id = ?&amp;quot; /&amp;gt; &amp;lt;sql-case id=&amp;quot;select_with_same_table_name_and_alias_column_with_owner&amp;quot; value=&amp;quot;SELECT t_order.order_id,t_order.user_id,status FROM t_order t_order WHERE t_order.user_id = ? AND order_id = ?&amp;quot; db-types=&amp;quot;MySQL,H2&amp;quot;/&amp;gt; &amp;lt;/sql-cases&amp;gt;  开发者通过该文件指定待断言的 SQL 以及该 SQL 所适配的数据库类型。将 sharding-sql-test 提取为单独的模块，以保证每个 SQL 用例可以在不同模块的测试引擎中共享。</description>
    </item>
    
    <item>
      <title>Sharding-JDBC</title>
      <link>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/quick-start/sharding-jdbc-quick-start/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/quick-start/sharding-jdbc-quick-start/</guid>
      <description> 1. 引入maven依赖 &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.apache.shardingsphere&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;sharding-jdbc-core&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;${latest.release.version}&amp;lt;/version&amp;gt; &amp;lt;/dependency&amp;gt;  注意: 请将${latest.release.version}更改为实际的版本号。
2. 规则配置 Sharding-JDBC可以通过Java，YAML，Spring命名空间和Spring Boot Starter四种方式配置，开发者可根据场景选择适合的配置方式。详情请参见配置手册。
3. 创建DataSource 通过ShardingDataSourceFactory工厂和规则配置对象获取ShardingDataSource，ShardingDataSource实现自JDBC的标准接口DataSource。然后即可通过DataSource选择使用原生JDBC开发，或者使用JPA, MyBatis等ORM工具。
DataSource dataSource = ShardingDataSourceFactory.createDataSource(dataSourceMap, shardingRuleConfig, props);  </description>
    </item>
    
    <item>
      <title>两阶段事务-XA</title>
      <link>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/transaction/concept/2pc-xa-transaction/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/transaction/concept/2pc-xa-transaction/</guid>
      <description>两阶段事务提交采用的是X/OPEN组织所定义的DTP模型，通过抽象出来的AP, TM, RM的概念可以保证事务的强一致性。 其中TM和RM间采用XA的协议进行双向通信。 与传统的本地事务相比，XA事务增加了prepare阶段，数据库除了被动接受提交指令外，还可以反向通知调用方事务是否可以被提交。 因此TM可以收集所有分支事务的prepare结果，最后进行原子的提交，保证事务的强一致性。
Java通过定义JTA接口实现了XA的模型，JTA接口里的ResourceManager需要数据库厂商提供XA的驱动实现，而TransactionManager则需要事务管理器的厂商实现，传统的事务管理器需要同应用服务器绑定，因此使用的成本很高。 而嵌入式的事务管器可以以jar包的形式提供服务，同ShardingSphere集成后，可保证分片后跨库事务强一致性。
通常，只有使用了事务管理器厂商所提供的XA事务连接池，才能支持XA的事务。ShardingSphere整合XA事务时，分离了XA事务管理和连接池管理，这样接入XA时，可以做到对业务的零侵入。</description>
    </item>
    
    <item>
      <title>使用手册</title>
      <link>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/manual/sharding-proxy/usage/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/manual/sharding-proxy/usage/</guid>
      <description>Proxy启动  下载Sharding-Proxy的最新发行版。 如果使用docker，可以执行docker pull shardingsphere/sharding-proxy获取镜像。详细信息请参考Docker镜像。 解压缩后修改conf/server.yaml和以config-前缀开头的文件，如：conf/config-xxx.yaml文件，进行分片规则、读写分离规则配置. 配置方式请参考配置手册。 Linux操作系统请运行bin/start.sh，Windows操作系统请运行bin/start.bat启动Sharding-Proxy。如需配置启动端口、配置文件位置，可参考快速入门 进行启动。 使用任何PostgreSQL的客户端连接。如: psql -U root -h 127.0.0.1 -p 3307  注册中心使用 若想使用Sharding-Proxy的数据库治理功能，则需要使用注册中心实现实例熔断和从库禁用功能。详情请参考支持的注册中心。
Zookeeper  Sharding-Proxy默认提供了Zookeeper的注册中心解决方案。您只需按照配置规则进行注册中心的配置，即可使用。  其他第三方注册中心  将Sharding-Proxy的lib目录下的sharding-orchestration-reg-zookeeper-curator-${sharding-sphere.version}.jar文件删除。 使用SPI方式实现相关逻辑编码，并将生成的jar包放到Sharding-Proxy的lib目录下。 按照配置规则进行注册中心的配置，即可使用。  使用自定义分片算法 当用户需要使用自定义的分片算法类时，无法再通过简单的inline表达式在yaml文件进行配置。可通过以下方式配置使用自定义分片算法。
 实现ShardingAlgorithm接口定义的算法实现类。 将上述java文件打包成jar包。 将上述jar包拷贝至ShardingProxy解压后的conf/lib目录下。 将上述自定义算法实现类的java文件引用配置在yaml文件里tableRule的algorithmClassName属性上，具体可参考配置规则。  分布式事务 Sharding-Proxy接入的分布式事务API同Sharding-JDBC保持一致，支持LOCAL，XA，BASE类型的事务。
XA事务 Sharding-Proxy原生支持XA事务，默认的事务管理器为Atomikos。 可以通过在Sharding-Proxy的conf目录中添加jta.properties来定制化Atomikos配置项。 具体的配置规则请参考Atomikos的官方文档。
BASE事务 BASE目前没有打包到Sharding-Proxy中，使用时需要将实现了ShardingTransactionManagerSPI的jar拷贝至conf/lib目录，然后切换事务类型为BASE。
SCTL (Sharding-Proxy control language) SCTL为Sharding-Proxy特有的控制语句，可以在运行时修改和查询Sharding-Proxy的状态，目前支持的语法为：
   语句 说明     sctl:set transaction_type=XX 修改当前TCP连接的事务类型, 支持LOCAL，XA，BASE。例：sctl:set transaction_type=XA   sctl:show transaction_type 查询当前TCP连接的事务类型   sctl:show cached_connections 查询当前TCP连接中缓存的物理数据库连接个数   sctl:explain SQL语句 查看逻辑SQL的执行计划，例：sctl:explain select * from t_order;   sctl:hint set MASTER_ONLY=true 针对当前TCP连接，是否将数据库操作强制路由到主库   sctl:hint set DatabaseShardingValue=yy 针对当前TCP连接，设置hint仅对数据库分片有效，并添加分片值，yy：数据库分片值   sctl:hint addDatabaseShardingValue xx=yy 针对当前TCP连接，为表xx添加分片值yy，xx：逻辑表名称，yy：数据库分片值   sctl:hint addTableShardingValue xx=yy 针对当前TCP连接，为表xx添加分片值yy，xx：逻辑表名称，yy：表分片值   sctl:hint clear 针对当前TCP连接，清除hint所有设置   sctl:hint show status 针对当前TCP连接，查询hint状态，master_only:true/false，sharding_type:databases_only/databases_tables   sctl:hint show table status 针对当前TCP连接，查询逻辑表的hint分片值    Sharding-Proxy 默认不支持hint，如需支持，请在conf/server.</description>
    </item>
    
    <item>
      <title>数据分片</title>
      <link>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/manual/sharding-jdbc/usage/sharding/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/manual/sharding-jdbc/usage/sharding/</guid>
      <description>不使用Spring 引入Maven依赖 &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.apache.shardingsphere&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;sharding-jdbc-core&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;${sharding-sphere.version}&amp;lt;/version&amp;gt; &amp;lt;/dependency&amp;gt;  基于Java编码的规则配置 Sharding-JDBC的分库分表通过规则配置描述，以下例子是根据user_id取模分库, 且根据order_id取模分表的两库两表的配置。
// 配置真实数据源 Map&amp;lt;String, DataSource&amp;gt; dataSourceMap = new HashMap&amp;lt;&amp;gt;(); // 配置第一个数据源 BasicDataSource dataSource1 = new BasicDataSource(); dataSource1.setDriverClassName(&amp;quot;com.mysql.jdbc.Driver&amp;quot;); dataSource1.setUrl(&amp;quot;jdbc:mysql://localhost:3306/ds0&amp;quot;); dataSource1.setUsername(&amp;quot;root&amp;quot;); dataSource1.setPassword(&amp;quot;&amp;quot;); dataSourceMap.put(&amp;quot;ds0&amp;quot;, dataSource1); // 配置第二个数据源 BasicDataSource dataSource2 = new BasicDataSource(); dataSource2.setDriverClassName(&amp;quot;com.mysql.jdbc.Driver&amp;quot;); dataSource2.setUrl(&amp;quot;jdbc:mysql://localhost:3306/ds1&amp;quot;); dataSource2.setUsername(&amp;quot;root&amp;quot;); dataSource2.setPassword(&amp;quot;&amp;quot;); dataSourceMap.put(&amp;quot;ds1&amp;quot;, dataSource2); // 配置Order表规则 TableRuleConfiguration orderTableRuleConfig = new TableRuleConfiguration(&amp;quot;t_order&amp;quot;,&amp;quot;ds${0..1}.t_order${0..1}&amp;quot;); // 配置分库 + 分表策略 orderTableRuleConfig.setDatabaseShardingStrategyConfig(new InlineShardingStrategyConfiguration(&amp;quot;user_id&amp;quot;, &amp;quot;ds${user_id % 2}&amp;quot;)); orderTableRuleConfig.setTableShardingStrategyConfig(new InlineShardingStrategyConfiguration(&amp;quot;order_id&amp;quot;, &amp;quot;t_order${order_id % 2}&amp;quot;)); // 配置分片规则 ShardingRuleConfiguration shardingRuleConfig = new ShardingRuleConfiguration(); shardingRuleConfig.</description>
    </item>
    
    <item>
      <title>本地事务</title>
      <link>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/transaction/function/local-transaction/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/transaction/function/local-transaction/</guid>
      <description> 功能  完全支持非跨库事务，例如：仅分表，或分库但是路由的结果在单库中。
 完全支持因逻辑异常导致的跨库事务。例如：同一事务中，跨两个库更新。更新完毕后，抛出空指针，则两个库的内容都能回滚。
 不支持因网络、硬件异常导致的跨库事务。例如：同一事务中，跨两个库更新，更新完毕后、未提交之前，第一个库宕机，则只有第二个库数据提交。
  支持情况  Sharding-JDBC和Sharding-Proxy原生支持本地事务  </description>
    </item>
    
    <item>
      <title>核心概念</title>
      <link>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/read-write-split/concept/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/read-write-split/concept/</guid>
      <description>主库 添加、更新以及删除数据操作所使用的数据库，目前仅支持单主库。
从库 查询数据操作所使用的数据库，可支持多从库。
主从同步 将主库的数据异步的同步到从库的操作。由于主从同步的异步性，从库与主库的数据会短时间内不一致。
负载均衡策略 通过负载均衡策略将查询请求疏导至不同从库。</description>
    </item>
    
    <item>
      <title>行表达式</title>
      <link>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/sharding/other-features/inline-expression/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/sharding/other-features/inline-expression/</guid>
      <description>实现动机 配置的简化与一体化是行表达式所希望解决的两个主要问题。
在繁琐的数据分片规则配置中，随着数据节点的增多，大量的重复配置使得配置本身不易被维护。通过行表达式可以有效的简化数据节点配置工作量。
对于常见的分片算法，使用Java代码实现并不有助于配置的统一管理。通过行表达式书写分片算法，可以有效的将规则配置一同存放，更加易于浏览与存储。
语法说明 行表达式的使用非常直观，只需要在配置中使用${ expression }或$-&amp;gt;{ expression }标识行表达式即可。 目前支持数据节点和分片算法这两个部分的配置。行表达式的内容使用的是Groovy的语法，Groovy能够支持的所有操作，行表达式均能够支持。例如：
${begin..end}表示范围区间
${[unit1, unit2, unit_x]}表示枚举值
行表达式中如果出现连续多个${ expression }或$-&amp;gt;{ expression }表达式，整个表达式最终的结果将会根据每个子表达式的结果进行笛卡尔组合。
例如，以下行表达式：
${[&#39;online&#39;, &#39;offline&#39;]}_table${1..3}  最终会解析为：
online_table1, online_table2, online_table3, offline_table1, offline_table2, offline_table3  配置数据节点 对于均匀分布的数据节点，如果数据结构如下：
db0 ├── t_order0 └── t_order1 db1 ├── t_order0 └── t_order1  用行表达式可以简化为：
db${0..1}.t_order${0..1}  或者
db$-&amp;gt;{0..1}.t_order$-&amp;gt;{0..1}  对于自定义的数据节点，如果数据结构如下：
db0 ├── t_order0 └── t_order1 db1 ├── t_order2 ├── t_order3 └── t_order4  用行表达式可以简化为：
db0.t_order${0..1},db1.t_order${2..4}  或者</description>
    </item>
    
    <item>
      <title>解析引擎</title>
      <link>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/sharding/principle/parse/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/sharding/principle/parse/</guid>
      <description>相对于其他编程语言，SQL是比较简单的。 不过，它依然是一门完善的编程语言，因此对SQL的语法进行解析，与解析其他编程语言（如：Java语言、C语言、Go语言等）并无本质区别。
抽象语法树 解析过程分为词法解析和语法解析。 词法解析器用于将SQL拆解为不可再分的原子符号，称为Token。并根据不同数据库方言所提供的字典，将其归类为关键字，表达式，字面量和操作符。 再使用语法解析器将SQL转换为抽象语法树。
例如，以下SQL：
SELECT id, name FROM t_user WHERE status = &#39;ACTIVE&#39; AND age &amp;gt; 18  解析之后的为抽象语法树见下图。
为了便于理解，抽象语法树中的关键字的Token用绿色表示，变量的Token用红色表示，灰色表示需要进一步拆分。
最后，通过对抽象语法树的遍历去提炼分片所需的上下文，并标记有可能需要改写的位置。 供分片使用的解析上下文包含查询选择项（Select Items）、表信息（Table）、分片条件（Sharding Condition）、自增主键信息（Auto increment Primary Key）、排序信息（Order By）、分组信息（Group By）以及分页信息（Limit、Rownum、Top）。 SQL的一次解析过程是不可逆的，一个个Token的按SQL原本的顺序依次进行解析，性能很高。 考虑到各种数据库SQL方言的异同，在解析模块提供了各类数据库的SQL方言字典。
SQL解析引擎 SQL解析作为分库分表类产品的核心，其性能和兼容性是最重要的衡量指标。 ShardingSphere的SQL解析器经历了3代产品的更新迭代。
第一代SQL解析器为了追求性能与快速实现，在1.4.x之前的版本使用Druid作为SQL解析器。经实际测试，它的性能远超其它解析器。
第二代SQL解析器从1.5.x版本开始，ShardingSphere采用完全自研的SQL解析引擎。 由于目的不同，ShardingSphere并不需要将SQL转为一颗完全的抽象语法树，也无需通过访问器模式进行二次遍历。它采用对SQL半理解的方式，仅提炼数据分片需要关注的上下文，因此SQL解析的性能和兼容性得到了进一步的提高。
第三代SQL解析器则从3.0.x版本开始，ShardingSphere尝试使用ANTLR作为SQL解析的引擎，并计划根据DDL -&amp;gt; TCL -&amp;gt; DAL –&amp;gt; DCL -&amp;gt; DML –&amp;gt;DQL这个顺序，依次替换原有的解析引擎，目前仍处于替换迭代中。 使用ANTLR的原因是希望ShardingSphere的解析引擎能够更好的对SQL进行兼容。对于复杂的表达式、递归、子查询等语句，虽然ShardingSphere的分片核心并不关注，但是会影响对于SQL理解的友好度。 经过实例测试，ANTLR解析SQL的性能比自研的SQL解析引擎慢3-10倍左右。为了弥补这一差距，ShardingSphere将使用PreparedStatement的SQL解析的语法树放入缓存。 因此建议采用PreparedStatement这种SQL预编译的方式提升性能。
第三代SQL解析引擎的整体结构划分如下图所示。</description>
    </item>
    
    <item>
      <title>部署运行</title>
      <link>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/manual/sharding-ui/usage/build/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/manual/sharding-ui/usage/build/</guid>
      <description>二进制运行  git clone https://github.com/apache/incubator-shardingsphere.git； 运行 mvn clean install -Prelease； 获取安装包 /sharding-distribution/shardingsphere-ui-distribution/target/apache-shardingsphere-incubating-${latest.release.version}-sharding-ui-bin.tar.gz； 解压缩后运行bin/start.sh； 访问http://localhost:8088/。  源码调试模式 Sharding-UI采用前后端分离的方式。
后端  后端程序执行入口为org.apache.shardingsphere.ui.Bootstrap； 访问http://localhost:8088/。  前端  进入sharding-ui-frontend/目录； 执行npm install； 执行npm run dev； 访问http://localhost:8080/。  配置 Sharding-UI的配置文件为conf/application.properties, 它由两部分组成。
 程序监听端口； 登录身份验证信息。  server.port=8088 user.admin.username=admin user.admin.password=admin  注意事项  若使用maven构建后，再进行本地运行前端项目时，可能因为node版本不一致导致运行失败，可以清空node_modules/目录后重新运行。 错误日志如下：  ERROR Failed to compile with 17 errors error in ./src/views/orchestration/module/instance.vue?vue&amp;amp;type=style&amp;amp;index=0&amp;amp;id=9e59b740&amp;amp;lang=scss&amp;amp;scoped=true&amp;amp; Module build failed (from ./node_modules/sass-loader/dist/cjs.js): Error: Missing binding /sharding-sphere/sharding-ui/sharding-ui-frontend/node_modules/node-sass/vendor/darwin-x64-57/binding.node Node Sass could not find a binding for your current environment: OS X 64-bit with Node.</description>
    </item>
    
    <item>
      <title>配置中心</title>
      <link>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/orchestration/config-center/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/orchestration/config-center/</guid>
      <description>实现动机  配置集中化：越来越多的运行时实例，使得散落的配置难于管理，配置不同步导致的问题十分严重。将配置集中于配置中心，可以更加有效进行管理。
 配置动态化：配置修改后的分发，是配置中心可以提供的另一个重要能力。它可支持数据源、表与分片及读写分离策略的动态切换。
  配置中心数据结构 配置中心在定义的命名空间的config下，以YAML格式存储，包括数据源，数据分片，读写分离、Properties配置，可通过修改节点来实现对于配置的动态管理。
config ├──authentication # Sharding-Proxy权限配置 ├──props # 属性配置 ├──schema # Schema配置 ├ ├──sharding_db # SchemaName配置 ├ ├ ├──datasource # 数据源配置 ├ ├ ├──rule # 数据分片规则配置 ├ ├──masterslave_db # SchemaName配置 ├ ├ ├──datasource # 数据源配置 ├ ├ ├──rule # 读写分离规则  config/authentication password: root username: root  config/sharding/props 相对于sharding-sphere配置里面的Sharding Properties。
executor.size: 20 sql.show: true  config/schema/schemeName/datasource 多个数据库连接池的集合，不同数据库连接池属性自适配（例如：DBCP，C3P0，Druid, HikariCP）。
ds_0: !!org.apache.shardingsphere.orchestration.yaml.YamlDataSourceConfiguration dataSourceClassName: com.zaxxer.hikari.HikariDataSource properties: url: jdbc:mysql://127.</description>
    </item>
    
    <item>
      <title>Sharding-Proxy</title>
      <link>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/quick-start/sharding-proxy-quick-start/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/quick-start/sharding-proxy-quick-start/</guid>
      <description> 1. 规则配置 编辑%SHARDING_PROXY_HOME%\conf\config-xxx.yaml。详情请参见配置手册。
编辑%SHARDING_PROXY_HOME%\conf\server.yaml。详情请参见配置手册。
2. 引入依赖 如果后端连接PostgreSQL数据库，不需要引入额外依赖。
如果后端连接MySQL数据库，需要下载MySQL Connector/J， 解压缩后，将mysql-connector-java-5.1.47.jar拷贝到${sharding-proxy}\lib目录。
3. 启动服务  使用默认配置项  ${sharding-proxy}\bin\start.sh   配置端口  ${sharding-proxy}\bin\start.sh ${port}  </description>
    </item>
    
    <item>
      <title>Yaml配置</title>
      <link>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/manual/sharding-jdbc/configuration/config-yaml/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/manual/sharding-jdbc/configuration/config-yaml/</guid>
      <description>配置示例 数据分片 dataSources: ds0: !!org.apache.commons.dbcp.BasicDataSource driverClassName: com.mysql.jdbc.Driver url: jdbc:mysql://localhost:3306/ds0 username: root password: ds1: !!org.apache.commons.dbcp.BasicDataSource driverClassName: com.mysql.jdbc.Driver url: jdbc:mysql://localhost:3306/ds1 username: root password: shardingRule: tables: t_order: actualDataNodes: ds${0..1}.t_order${0..1} databaseStrategy: inline: shardingColumn: user_id algorithmExpression: ds${user_id % 2} tableStrategy: inline: shardingColumn: order_id algorithmExpression: t_order${order_id % 2} keyGenerator: type: SNOWFLAKE column: order_id t_order_item: actualDataNodes: ds${0..1}.t_order_item${0..1} databaseStrategy: inline: shardingColumn: user_id algorithmExpression: ds${user_id % 2} tableStrategy: inline: shardingColumn: order_id algorithmExpression: t_order_item${order_id % 2} bindingTables: - t_order,t_order_item broadcastTables: - t_config defaultDataSourceName: ds0 defaultTableStrategy: none: defaultKeyGenerator: type: SNOWFLAKE column: order_id props: sql.</description>
    </item>
    
    <item>
      <title>两阶段事务-XA</title>
      <link>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/transaction/function/2pc-xa-transaction/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/transaction/function/2pc-xa-transaction/</guid>
      <description> 功能  支持数据分片后的跨库XA事务 两阶段提交保证操作的原子性和数据的强一致性 服务宕机重启后，提交/回滚中的事务可自动恢复 SPI机制整合主流的XA事务管理器，默认Atomikos，可以选择使用Narayana和Bitronix 同时支持XA和非XA的连接池 提供spring-boot和namespace的接入端  不支持项  服务宕机后，在其它机器上恢复提交/回滚中的数据  </description>
    </item>
    
    <item>
      <title>两阶段事务-XA</title>
      <link>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/transaction/principle/2pc-xa-transaction/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/transaction/principle/2pc-xa-transaction/</guid>
      <description> 实现原理 ShardingSphere里定义了分布式事务的SPI接口ShardingTransactionManager，Sharding-JDBC和Sharding-Proxy为分布式事务的两个接入端。XAShardingTransactionManager为分布式事务的XA实现类，通过引入sharding-transaction-xa-core依赖，即可加入ShardingSphere 的分布式事务生态中。XAShardingTransactionManager主要负责对actual datasource进行管理和适配，并且将接入端事务的begin/commit/rollback操作委托给具体的XA事务管理器。
1.Begin（开启XA全局事务） 通常收到接入端的set autoCommit=0时，XAShardingTransactionManager会调用具体的XA事务管理器开启XA的全局事务，通常以XID的形式进行标记。
2.执行物理SQL ShardingSphere进行解析/优化/路由后，会生成逻辑SQL的分片SQLUnit，执行引擎为每个物理SQL创建连接的同时，物理连接所对应的XAResource也会被注册到当前XA事务中，事务管理器会在此阶段发送XAResource.start命令给数据库，数据库在收到XAResource.end命令之前的所有SQL操作，会被标记为XA事务。
例如:
XAResource1.start ## Enlist阶段执行 statement.execute(&amp;quot;sql1&amp;quot;); ## 模拟执行一个分片SQL1 statement.execute(&amp;quot;sql2&amp;quot;); ## 模拟执行一个分片SQL2 XAResource1.end ## 提交阶段执行  这里sql1和sql2将会被标记为XA事务。
3.Commit/rollback（提交XA事务） XAShardingTransactionManager收到接入端的提交命令后，会委托实际的XA事务管理进行提交动作，这时事务管理器会收集当前线程里所有注册的XAResource，首先发送XAResource.end指令，用以标记此XA事务的边界。 接着会依次发送prepare指令，收集所有参与XAResource投票，如果所有XAResource的反馈结果都是OK，则会再次调用commit指令进行最终提交，如果有一个XAResource的反馈结果为No，则会调用rollback指令进行回滚。 在事务管理器发出提交指令后，任何XAResource产生的异常都会通过recovery日志进行重试，来保证提交阶段的操作原子性，和数据强一致性。
例如:
XAResource1.prepare ## ack: yes XAResource2.prepare ## ack: yes XAResource1.commit XAResource2.commit XAResource1.prepare ## ack: yes XAResource2.prepare ## ack: no XAResource1.rollback XAResource2.rollback  </description>
    </item>
    
    <item>
      <title>分布式主键</title>
      <link>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/sharding/other-features/key-generator/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/sharding/other-features/key-generator/</guid>
      <description>实现动机 传统数据库软件开发中，主键自动生成技术是基本需求。而各个数据库对于该需求也提供了相应的支持，比如MySQL的自增键，Oracle的自增序列等。 数据分片后，不同数据节点生成全局唯一主键是非常棘手的问题。同一个逻辑表内的不同实际表之间的自增键由于无法互相感知而产生重复主键。 虽然可通过约束自增主键初始值和步长的方式避免碰撞，但需引入额外的运维规则，使解决方案缺乏完整性和可扩展性。
目前有许多第三方解决方案可以完美解决这个问题，如UUID等依靠特定算法自生成不重复键，或者通过引入主键生成服务等。为了方便用户使用、满足不同用户不同使用场景的需求， ShardingSphere不仅提供了内置的分布式主键生成器，例如UUID、SNOWFLAKE、LEAF(进行中)，还抽离出分布式主键生成器的接口，方便用户自行实现自定义的自增主键生成器。
内置的主键生成器 UUID 采用UUID.randomUUID()的方式产生分布式主键。
SNOWFLAKE ShardingSphere提供灵活的配置分布式主键生成策略方式。 在分片规则配置模块可配置每个表的主键生成策略，默认使用雪花算法（snowflake）生成64bit的长整型数据。
雪花算法是由Twitter公布的分布式主键生成算法，它能够保证不同进程主键的不重复性，以及相同进程主键的有序性。
在同一个进程中，它首先是通过时间位保证不重复，如果时间相同则是通过序列位保证。 同时由于时间位是单调递增的，且各个服务器如果大体做了时间同步，那么生成的主键在分布式环境可以认为是总体有序的，这就保证了对索引字段的插入的高效性。例如MySQL的Innodb存储引擎的主键。
使用雪花算法生成的主键，二进制表示形式包含4部分，从高位到低位分表为：1bit符号位、41bit时间戳位、10bit工作进程位以及12bit序列号位。
 符号位(1bit)  预留的符号位，恒为零。
 时间戳位(41bit)  41位的时间戳可以容纳的毫秒数是2的41次幂，一年所使用的毫秒数是：365 * 24 * 60 * 60 * 1000。通过计算可知：
Math.pow(2, 41) / (365 * 24 * 60 * 60 * 1000L);  结果约等于69.73年。ShardingSphere的雪花算法的时间纪元从2016年11月1日零点开始，可以使用到2086年，相信能满足绝大部分系统的要求。
 工作进程位(10bit)  该标志在Java进程内是唯一的，如果是分布式应用部署应保证每个工作进程的id是不同的。该值默认为0，可通过属性设置。
 序列号位(12bit)  该序列是用来在同一个毫秒内生成不同的ID。如果在这个毫秒内生成的数量超过4096(2的12次幂)，那么生成器会等待到下个毫秒继续生成。
时钟回拨 服务器时钟回拨会导致产生重复序列，因此默认分布式主键生成器提供了一个最大容忍的时钟回拨毫秒数。 如果时钟回拨的时间超过最大容忍的毫秒数阈值，则程序报错；如果在可容忍的范围内，默认分布式主键生成器会等待时钟同步到最后一次主键生成的时间后再继续工作。 最大容忍的时钟回拨毫秒数的默认值为0，可通过属性设置。
雪花算法主键的详细结构见下图。
LEAF 借鉴Leaf, 主要分为Leaf-segment和Leaf-snowflake两种方案。 ShardingSphere在4.0.0-RC2-release版本中实现了Leaf-segment,在4.0.0-RC3-release版本中实现了Leaf-snowflake。</description>
    </item>
    
    <item>
      <title>分片</title>
      <link>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/sharding/concept/sharding/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/sharding/concept/sharding/</guid>
      <description>分片键 用于分片的数据库字段，是将数据库(表)水平拆分的关键字段。例：将订单表中的订单主键的尾数取模分片，则订单主键为分片字段。 SQL中如果无分片字段，将执行全路由，性能较差。 除了对单分片字段的支持，ShardingSphere也支持根据多个字段进行分片。
分片算法 通过分片算法将数据分片，支持通过=、&amp;gt;=、&amp;lt;=、&amp;gt;、&amp;lt;、BETWEEN和IN分片。分片算法需要应用方开发者自行实现，可实现的灵活度非常高。
目前提供4种分片算法。由于分片算法和业务实现紧密相关，因此并未提供内置分片算法，而是通过分片策略将各种场景提炼出来，提供更高层级的抽象，并提供接口让应用开发者自行实现分片算法。
 精确分片算法  对应PreciseShardingAlgorithm，用于处理使用单一键作为分片键的=与IN进行分片的场景。需要配合StandardShardingStrategy使用。
 范围分片算法  对应RangeShardingAlgorithm，用于处理使用单一键作为分片键的BETWEEN AND、&amp;gt;、&amp;lt;、&amp;gt;=、&amp;lt;=进行分片的场景。需要配合StandardShardingStrategy使用。
 复合分片算法  对应ComplexKeysShardingAlgorithm，用于处理使用多键作为分片键进行分片的场景，包含多个分片键的逻辑较复杂，需要应用开发者自行处理其中的复杂度。需要配合ComplexShardingStrategy使用。
 Hint分片算法  对应HintShardingAlgorithm，用于处理使用Hint行分片的场景。需要配合HintShardingStrategy使用。
分片策略 包含分片键和分片算法，由于分片算法的独立性，将其独立抽离。真正可用于分片操作的是分片键 + 分片算法，也就是分片策略。目前提供5种分片策略。
 标准分片策略  对应StandardShardingStrategy。提供对SQL语句中的=, &amp;gt;, &amp;lt;, &amp;gt;=, &amp;lt;=, IN和BETWEEN AND的分片操作支持。StandardShardingStrategy只支持单分片键，提供PreciseShardingAlgorithm和RangeShardingAlgorithm两个分片算法。PreciseShardingAlgorithm是必选的，用于处理=和IN的分片。RangeShardingAlgorithm是可选的，用于处理BETWEEN AND, &amp;gt;, &amp;lt;, &amp;gt;=, &amp;lt;=分片，如果不配置RangeShardingAlgorithm，SQL中的BETWEEN AND将按照全库路由处理。
 复合分片策略  对应ComplexShardingStrategy。复合分片策略。提供对SQL语句中的=, &amp;gt;, &amp;lt;, &amp;gt;=, &amp;lt;=, IN和BETWEEN AND的分片操作支持。ComplexShardingStrategy支持多分片键，由于多分片键之间的关系复杂，因此并未进行过多的封装，而是直接将分片键值组合以及分片操作符透传至分片算法，完全由应用开发者实现，提供最大的灵活度。
 行表达式分片策略  对应InlineShardingStrategy。使用Groovy的表达式，提供对SQL语句中的=和IN的分片操作支持，只支持单分片键。对于简单的分片算法，可以通过简单的配置使用，从而避免繁琐的Java代码开发，如: t_user_$-&amp;gt;{u_id % 8} 表示t_user表根据u_id模8，而分成8张表，表名称为t_user_0到t_user_7。
 Hint分片策略  对应HintShardingStrategy。通过Hint而非SQL解析的方式分片的策略。
 不分片策略  对应NoneShardingStrategy。不分片的策略。</description>
    </item>
    
    <item>
      <title>分页</title>
      <link>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/sharding/use-norms/pagination/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/sharding/use-norms/pagination/</guid>
      <description>完全支持MySQL、PostgreSQL和Oracle的分页查询，SQLServer由于分页查询较为复杂，仅部分支持。
分页性能 性能瓶颈 查询偏移量过大的分页会导致数据库获取数据性能低下，以MySQL为例：
SELECT * FROM t_order ORDER BY id LIMIT 1000000, 10  这句SQL会使得MySQL在无法利用索引的情况下跳过1000000条记录后，再获取10条记录，其性能可想而知。 而在分库分表的情况下（假设分为2个库），为了保证数据的正确性，SQL会改写为：
SELECT * FROM t_order ORDER BY id LIMIT 0, 1000010  即将偏移量前的记录全部取出，并仅获取排序后的最后10条记录。这会在数据库本身就执行很慢的情况下，进一步加剧性能瓶颈。 因为原SQL仅需要传输10条记录至客户端，而改写之后的SQL则会传输1,000,010 * 2的记录至客户端。
ShardingSphere的优化 ShardingSphere进行了2个方面的优化。
首先，采用流式处理 + 归并排序的方式来避免内存的过量占用。由于SQL改写不可避免的占用了额外的带宽，但并不会导致内存暴涨。 与直觉不同，大多数人认为ShardingSphere会将1,000,010 * 2记录全部加载至内存，进而占用大量内存而导致内存溢出。 但由于每个结果集的记录是有序的，因此ShardingSphere每次比较仅获取各个分片的当前结果集记录，驻留在内存中的记录仅为当前路由到的分片的结果集的当前游标指向而已。 对于本身即有序的待排序对象，归并排序的时间复杂度仅为O(n)，性能损耗很小。
其次，ShardingSphere对仅落至单分片的查询进行进一步优化。 落至单分片查询的请求并不需要改写SQL也可以保证记录的正确性，因此在此种情况下，ShardingSphere并未进行SQL改写，从而达到节省带宽的目的。
分页方案优化 由于LIMIT并不能通过索引查询数据，因此如果可以保证ID的连续性，通过ID进行分页是比较好的解决方案：
SELECT * FROM t_order WHERE id &amp;gt; 100000 AND id &amp;lt;= 100010 ORDER BY id  或通过记录上次查询结果的最后一条记录的ID进行下一页的查询：
SELECT * FROM t_order WHERE id &amp;gt; 100000 LIMIT 10  分页子查询 Oracle和SQLServer的分页都需要通过子查询来处理，ShardingSphere支持分页相关的子查询。</description>
    </item>
    
    <item>
      <title>整合测试引擎</title>
      <link>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/test-engine/integration-test-engine/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/test-engine/integration-test-engine/</guid>
      <description>流程 Junit 中的 Parameterized 会聚合起所有的测试数据，并将测试数据一一传递给测试方法进行断言。数据处理就像是沙漏中的流沙：
配置  环境类文件  /sharding-integration-test/sharding-jdbc-test/src/test/resources/integrate/env.properties /sharding-integration-test/sharding-jdbc-test/src/test/resources/integrate/env/SQL-TYPE/dataset.xml /sharding-integration-test/sharding-jdbc-test/src/test/resources/integrate/env/SQL-TYPE/schema.xml  测试用例类文件  /sharding-integration-test/sharding-jdbc-test/src/test/resources/integrate/cases/SQL-TYPE/SQL-TYPE-integrate-test-cases.xml /sharding-integration-test/sharding-jdbc-test/src/test/resources/integrate/cases/SQL-TYPE/dataset/SHARDING-TYPE/*.xml  sql-case 文件  /sharding-sql-test/src/main/resources/sql/sharding/SQL-TYPE/*.xml   环境配置 集成测试需要真实的数据库环境，根据相应的配置文件创建测试环境：
首先，修改配置文件 /sharding-integration-test/sharding-jdbc-test/src/test/resources/integrate/env.properties ，例子如下：
# 测试主键，并发，column index等的开关 run.additional.cases=false # 分片策略，可指定多种策略 sharding.rule.type=db,tbl,dbtbl_with_masterslave,masterslave # 要测试的数据库，可以指定多种数据库(H2,MySQL,Oracle,SQLServer,PostgreSQL) databases=MySQL,PostgreSQL # MySQL配置 mysql.host=127.0.0.1 mysql.port=13306 mysql.username=root mysql.password=root ## PostgreSQL配置 postgresql.host=db.psql postgresql.port=5432 postgresql.username=postgres postgresql.password= ## SQLServer配置 sqlserver.host=db.mssql sqlserver.port=1433 sqlserver.username=sa sqlserver.password=Jdbc1234 ## Oracle配置 oracle.host=db.oracle oracle.port=1521 oracle.username=jdbc oracle.password=jdbc  其次，修改文件 /sharding-integration-test/sharding-jdbc-test/src/test/resources/integrate/env/SQL-TYPE/dataset.xml 在dataset.xml文件中定义元数据和测试数据。例如：
&amp;lt;dataset&amp;gt; &amp;lt;metadata data-nodes=&amp;quot;tbl.</description>
    </item>
    
    <item>
      <title>核心功能</title>
      <link>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/read-write-split/core-features/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/read-write-split/core-features/</guid>
      <description> 提供一主多从的读写分离配置，可独立使用，也可配合分库分表使用。 独立使用读写分离支持SQL透传。 同一线程且同一数据库连接内，如有写入操作，以后的读操作均从主库读取，用于保证数据一致性。 基于Hint的强制主库路由。  </description>
    </item>
    
    <item>
      <title>注册中心</title>
      <link>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/manual/sharding-ui/usage/registry-center/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/manual/sharding-ui/usage/registry-center/</guid>
      <description>注册中心配置 首先需要添加并激活注册中心。可以添加多个注册中心，但只能有一个处于激活状态，后面的配置管理和编排治理功能都是针对当前已激活的注册中心进行操作。 目前提供Zookeeper的支持，后续会添加第三方注册中心的支持。
配置管理 可以获取当前注册中心中所有数据源的相关配置，包括数据分片，读写分离、Properties配置等。
可以通过YAML格式对相关配置信息进行修改。
编排治理 通过注册中心，可以进行熔断数据库访问程序对数据库的访问和禁用从库的操作。
熔断实例 可以查看当前运行实例信息，并进行熔断与恢复操作。
禁用从库 可以查看所有从库信息，并进行从库禁用与恢复操作。</description>
    </item>
    
    <item>
      <title>编排治理</title>
      <link>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/orchestration/orchestration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/orchestration/orchestration/</guid>
      <description> 实现动机 通过注册中心，提供熔断数据库访问程序对数据库的访问和禁用从库的访问的能力。治理仍然有大量未完成的功能。
注册中心数据结构 注册中心在定义的命名空间的state下，创建数据库访问对象运行节点，用于区分不同数据库访问实例。包括instances和datasources节点。
instances ├──your_instance_ip_a@-@your_instance_pid_x ├──your_instance_ip_b@-@your_instance_pid_y ├──.... datasources ├──ds0 ├──ds1 ├──....  Sharding-Proxy支持多逻辑数据源，因此datasources子节点的名称采用schema_name.data_source_name的形式。
instances ├──your_instance_ip_a@-@your_instance_pid_x ├──your_instance_ip_b@-@your_instance_pid_y ├──.... datasources ├──sharding_db.ds0 ├──sharding_db.ds1 ├──....  state/instances 数据库访问对象运行实例信息，子节点是当前运行实例的标识。 运行实例标识由运行服务器的IP地址和PID构成。运行实例标识均为临时节点，当实例上线时注册，下线时自动清理。 注册中心监控这些节点的变化来治理运行中实例对数据库的访问等。
state/datasources 可以治理读写分离从库，可动态添加删除以及禁用。
操作指南 熔断实例 可在IP地址@-@PID节点写入DISABLED（忽略大小写）表示禁用该实例，删除DISABLED表示启用。
Zookeeper命令如下：
[zk: localhost:2181(CONNECTED) 0] set /your_zk_namespace/your_app_name/state/instances/your_instance_ip_a@-@your_instance_pid_x DISABLED  禁用从库 在读写分离（或数据分片+读写分离）场景下，可在数据源名称子节点中写入DISABLED（忽略大小写）表示禁用从库数据源，删除DISABLED或节点表示启用。
Zookeeper命令如下：
[zk: localhost:2181(CONNECTED) 0] set /your_zk_namespace/your_app_name/state/datasources/your_slave_datasource_name DISABLED  </description>
    </item>
    
    <item>
      <title>读写分离</title>
      <link>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/manual/sharding-jdbc/usage/read-write-splitting/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/manual/sharding-jdbc/usage/read-write-splitting/</guid>
      <description>不使用Spring 引入Maven依赖 &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.apache.shardingsphere&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;sharding-jdbc-core&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;${sharding-sphere.version}&amp;lt;/version&amp;gt; &amp;lt;/dependency&amp;gt;  基于Java编码的规则配置 // 配置真实数据源 Map&amp;lt;String, DataSource&amp;gt; dataSourceMap = new HashMap&amp;lt;&amp;gt;(); // 配置主库 BasicDataSource masterDataSource = new BasicDataSource(); masterDataSource.setDriverClassName(&amp;quot;com.mysql.jdbc.Driver&amp;quot;); masterDataSource.setUrl(&amp;quot;jdbc:mysql://localhost:3306/ds_master&amp;quot;); masterDataSource.setUsername(&amp;quot;root&amp;quot;); masterDataSource.setPassword(&amp;quot;&amp;quot;); dataSourceMap.put(&amp;quot;ds_master&amp;quot;, masterDataSource); // 配置第一个从库 BasicDataSource slaveDataSource1 = new BasicDataSource(); slaveDataSource1.setDriverClassName(&amp;quot;com.mysql.jdbc.Driver&amp;quot;); slaveDataSource1.setUrl(&amp;quot;jdbc:mysql://localhost:3306/ds_slave0&amp;quot;); slaveDataSource1.setUsername(&amp;quot;root&amp;quot;); slaveDataSource1.setPassword(&amp;quot;&amp;quot;); dataSourceMap.put(&amp;quot;ds_slave0&amp;quot;, slaveDataSource1); // 配置第二个从库 BasicDataSource slaveDataSource2 = new BasicDataSource(); slaveDataSource2.setDriverClassName(&amp;quot;com.mysql.jdbc.Driver&amp;quot;); slaveDataSource2.setUrl(&amp;quot;jdbc:mysql://localhost:3306/ds_slave1&amp;quot;); slaveDataSource2.setUsername(&amp;quot;root&amp;quot;); slaveDataSource2.setPassword(&amp;quot;&amp;quot;); dataSourceMap.put(&amp;quot;ds_slave1&amp;quot;, slaveDataSource2); // 配置读写分离规则 MasterSlaveRuleConfiguration masterSlaveRuleConfig = new MasterSlaveRuleConfiguration(&amp;quot;ds_master_slave&amp;quot;, &amp;quot;ds_master&amp;quot;, Arrays.asList(&amp;quot;ds_slave0&amp;quot;, &amp;quot;ds_slave1&amp;quot;)); // 获取数据源对象 DataSource dataSource = MasterSlaveDataSourceFactory.</description>
    </item>
    
    <item>
      <title>路由引擎</title>
      <link>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/sharding/principle/route/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/sharding/principle/route/</guid>
      <description>根据解析上下文匹配数据库和表的分片策略，并生成路由路径。 对于携带分片键的SQL，根据分片键的不同可以划分为单片路由(分片键的操作符是等号)、多片路由(分片键的操作符是IN)和范围路由(分片键的操作符是BETWEEN)。 不携带分片键的SQL则采用广播路由。
分片策略通常可以采用由数据库内置或由用户方配置。 数据库内置的方案较为简单，内置的分片策略大致可分为尾数取模、哈希、范围、标签、时间等。 由用户方配置的分片策略则更加灵活，可以根据使用方需求定制复合分片策略。 如果配合数据自动迁移来使用，可以做到无需用户关注分片策略，自动由数据库中间层分片和平衡数据即可，进而做到使分布式数据库具有的弹性伸缩的能力。 在ShardingSphere的线路规划中，弹性伸缩将于4.x开启。
分片路由 用于根据分片键进行路由的场景，又细分为直接路由、标准路由和笛卡尔积路由这3种类型。
直接路由 满足直接路由的条件相对苛刻，它需要通过Hint（使用HintAPI直接指定路由至库表）方式分片，并且是只分库不分表的前提下，则可以避免SQL解析和之后的结果归并。 因此它的兼容性最好，可以执行包括子查询、自定义函数等复杂情况的任意SQL。直接路由还可以用于分片键不在SQL中的场景。例如，设置用于数据库分片的键为3，
hintManager.setDatabaseShardingValue(3);  假如路由算法为value % 2，当一个逻辑库t_order对应2个真实库t_order_0和t_order_1时，路由后SQL将在t_order_1上执行。下方是使用API的代码样例：
String sql = &amp;quot;SELECT * FROM t_order&amp;quot;; try ( HintManager hintManager = HintManager.getInstance(); Connection conn = dataSource.getConnection(); PreparedStatement pstmt = conn.prepareStatement(sql)) { hintManager.setDatabaseShardingValue(3); try (ResultSet rs = pstmt.executeQuery()) { while (rs.next()) { //... } } }  标准路由 标准路由是ShardingSphere最为推荐使用的分片方式，它的适用范围是不包含关联查询或仅包含绑定表之间关联查询的SQL。 当分片运算符是等于号时，路由结果将落入单库（表），当分片运算符是BETWEEN或IN时，则路由结果不一定落入唯一的库（表），因此一条逻辑SQL最终可能被拆分为多条用于执行的真实SQL。 举例说明，如果按照order_id的奇数和偶数进行数据分片，一个单表查询的SQL如下：
SELECT * FROM t_order WHERE order_id IN (1, 2);  那么路由的结果应为：</description>
    </item>
    
    <item>
      <title>配置手册</title>
      <link>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/manual/sharding-proxy/configuration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/manual/sharding-proxy/configuration/</guid>
      <description>数据源与分片配置示例 Sharding-Proxy支持多逻辑数据源，每个以config-前缀命名的yaml配置文件，即为一个逻辑数据源。以下是config-xxx.yaml的配置配置示例。
数据分片 dataSources:
schemaName: sharding_db dataSources: ds0: url: jdbc:postgresql://localhost:5432/ds0 username: root password: connectionTimeoutMilliseconds: 30000 idleTimeoutMilliseconds: 60000 maxLifetimeMilliseconds: 1800000 maxPoolSize: 65 ds1: url: jdbc:postgresql://localhost:5432/ds1 username: root password: connectionTimeoutMilliseconds: 30000 idleTimeoutMilliseconds: 60000 maxLifetimeMilliseconds: 1800000 maxPoolSize: 65 shardingRule: tables: t_order: actualDataNodes: ds${0..1}.t_order${0..1} databaseStrategy: inline: shardingColumn: user_id algorithmExpression: ds${user_id % 2} tableStrategy: inline: shardingColumn: order_id algorithmExpression: t_order${order_id % 2} keyGenerator: type: SNOWFLAKE column: order_id t_order_item: actualDataNodes: ds${0..1}.t_order_item${0..1} databaseStrategy: inline: shardingColumn: user_id algorithmExpression: ds${user_id % 2} tableStrategy: inline: shardingColumn: order_id algorithmExpression: t_order_item${order_id % 2} keyGenerator: type: SNOWFLAKE column: order_item_id bindingTables: - t_order,t_order_item defaultTableStrategy: none:  读写分离 schemaName: master_slave_db dataSources: ds_master: url: jdbc:postgresql://localhost:5432/ds_master username: root password: connectionTimeoutMilliseconds: 30000 idleTimeoutMilliseconds: 60000 maxLifetimeMilliseconds: 1800000 maxPoolSize: 65 ds_slave0: url: jdbc:postgresql://localhost:5432/ds_slave0 username: root password: connectionTimeoutMilliseconds: 30000 idleTimeoutMilliseconds: 60000 maxLifetimeMilliseconds: 1800000 maxPoolSize: 65 ds_slave1: url: jdbc:postgresql://localhost:5432/ds_slave1 username: root password: connectionTimeoutMilliseconds: 30000 idleTimeoutMilliseconds: 60000 maxLifetimeMilliseconds: 1800000 maxPoolSize: 65 masterSlaveRule: name: ds_ms masterDataSourceName: ds_master slaveDataSourceNames: - ds_slave0 - ds_slave1  数据脱敏 schemaName: encrypt_db dataSource: url: jdbc:mysql://127.</description>
    </item>
    
    <item>
      <title>Docker镜像</title>
      <link>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/manual/sharding-proxy/docker/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/manual/sharding-proxy/docker/</guid>
      <description>拉取官方Docker镜像 docker pull apache/sharding-proxy  手动构建Docker镜像（可选） git clone https://github.com/apache/incubator-shardingsphere mvn clean install cd sharding-sphere/sharding-distribution/sharding-proxy-distribution mvn clean package docker:build  配置Sharding-Proxy 创建/${your_work_dir}/conf/config.yaml文件，进行分片规则配置。配置方式请参考配置手册。
运行Docker docker run -d -v /${your_work_dir}/conf:/opt/sharding-proxy/conf --env PORT=3308 -p13308:3308 apache/sharding-proxy:latest  可以自定义端口3308和13308。3308表示docker容器端口, 13308表示宿主机端口。
docker run -d -v /${your_work_dir}/conf:/opt/sharding-proxy/conf --env JVM_OPTS=&amp;quot;-Djava.awt.headless=true&amp;quot; --env PORT=3308 -p13308:3308 apache/sharding-proxy:latest  可以自定义JVM相关参数到环境变量JVM_OPTS中。
访问Sharding-Proxy 与连接PostgreSQL的方式相同。
psql -U ${your_user_name} -h ${your_host} -p 13308  FAQ 问题1：I/O exception (java.io.IOException) caught when processing request to {}-&amp;gt;unix://localhost:80: Connection refused？</description>
    </item>
    
    <item>
      <title>JDBC不支持项</title>
      <link>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/manual/sharding-jdbc/unsupported-items/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/manual/sharding-jdbc/unsupported-items/</guid>
      <description>DataSource接口  不支持timeout相关操作  Connection接口  不支持存储过程，函数，游标的操作 不支持执行native的SQL 不支持savepoint相关操作 不支持Schema/Catalog的操作 不支持自定义类型映射  Statement和PreparedStatement接口  不支持返回多结果集的语句（即存储过程，非SELECT多条数据） 不支持国际化字符的操作  对于ResultSet接口  不支持对于结果集指针位置判断 不支持通过非next方法改变结果指针位置 不支持修改结果集内容 不支持获取国际化字符 不支持获取Array  JDBC 4.1  不支持JDBC 4.1接口新功能  查询所有未支持方法，请阅读org.apache.shardingsphere.shardingjdbc.jdbc.unsupported包。</description>
    </item>
    
    <item>
      <title>SQL解析测试引擎</title>
      <link>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/test-engine/parse-test-engine/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/test-engine/parse-test-engine/</guid>
      <description>数据准备 SQL解析不需要真实的测试环境，开发者只需定义好待测试的SQL，以及解析后的断言数据即可：
SQL数据 在集成测试的部分提到过sql-case-id，其对应的SQL，可以在不同模块共享。开发者只需要在/sharding-sql-test/src/main/resources/sql/sharding/SQL-TYPE/*.xml 添加待测试的SQL即可。
断言解析数据 断言的解析数据保存在 /sharding-core/sharding-core-parse/sharding-core-parse-test/src/test/resources/sharding/SQL-TYPE/*.xml 在xml文件中，可以针对表名，token，SQL条件等进行断言，例如如下的配置：
&amp;lt;parser-result-sets&amp;gt; &amp;lt;parser-result sql-case-id=&amp;quot;insert_with_multiple_values&amp;quot;&amp;gt; &amp;lt;tables&amp;gt; &amp;lt;table name=&amp;quot;t_order&amp;quot; /&amp;gt; &amp;lt;/tables&amp;gt; &amp;lt;tokens&amp;gt; &amp;lt;table-token start-index=&amp;quot;12&amp;quot; table-name=&amp;quot;t_order&amp;quot; length=&amp;quot;7&amp;quot; /&amp;gt; &amp;lt;/tokens&amp;gt; &amp;lt;sharding-conditions&amp;gt; &amp;lt;and-condition&amp;gt; &amp;lt;condition column-name=&amp;quot;order_id&amp;quot; table-name=&amp;quot;t_order&amp;quot; operator=&amp;quot;EQUAL&amp;quot;&amp;gt; &amp;lt;value literal=&amp;quot;1&amp;quot; type=&amp;quot;int&amp;quot; /&amp;gt; &amp;lt;/condition&amp;gt; &amp;lt;condition column-name=&amp;quot;user_id&amp;quot; table-name=&amp;quot;t_order&amp;quot; operator=&amp;quot;EQUAL&amp;quot;&amp;gt; &amp;lt;value literal=&amp;quot;1&amp;quot; type=&amp;quot;int&amp;quot; /&amp;gt; &amp;lt;/condition&amp;gt; &amp;lt;/and-condition&amp;gt; &amp;lt;and-condition&amp;gt; &amp;lt;condition column-name=&amp;quot;order_id&amp;quot; table-name=&amp;quot;t_order&amp;quot; operator=&amp;quot;EQUAL&amp;quot;&amp;gt; &amp;lt;value literal=&amp;quot;2&amp;quot; type=&amp;quot;int&amp;quot; /&amp;gt; &amp;lt;/condition&amp;gt; &amp;lt;condition column-name=&amp;quot;user_id&amp;quot; table-name=&amp;quot;t_order&amp;quot; operator=&amp;quot;EQUAL&amp;quot;&amp;gt; &amp;lt;value literal=&amp;quot;2&amp;quot; type=&amp;quot;int&amp;quot; /&amp;gt; &amp;lt;/condition&amp;gt; &amp;lt;/and-condition&amp;gt; &amp;lt;/sharding-conditions&amp;gt; &amp;lt;/parser-result&amp;gt; &amp;lt;/parser-result-sets&amp;gt;  设置好上面两类数据，开发者就可以通过 sharding-core-parse-test 下对应的engine启动SQL解析的测试了。</description>
    </item>
    
    <item>
      <title>Saga柔性事务</title>
      <link>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/transaction/concept/base-transaction-saga/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/transaction/concept/base-transaction-saga/</guid>
      <description>Saga事务 Saga这个概念来源于三十多年前的一篇数据库论文Sagas ，一个Saga事务是一个有多个短时事务组成的长时的事务。 在分布式事务场景下，我们把一个Saga分布式事务看做是一个由多个本地事务组成的事务，每个本地事务都有一个与之对应的补偿事务。在Saga事务的执行过程中，如果某一步执行出现异常，Saga事务会被终止，同时会调用对应的补偿事务完成相关的恢复操作，这样保证Saga相关的本地事务要么都是执行成功，要么通过补偿恢复成为事务执行之前的状态。
自动反向补偿 Saga定义了一个事务中的每个子事务都有一个与之对应的反向补偿操作。由Saga事务管理器根据程序执行结果生成一张有向无环图，并在需要执行回滚操作时，根据该图依次按照相反的顺序调用反向补偿操作。Saga事务管理器只用于控制何时重试，何时补偿，并不负责补偿的内容，补偿的具体操作需要由开发者自行提供。
ShardingSphere采用反向SQL技术，将对数据库进行更新操作的SQL自动生成反向SQL，并交由saga-actuator执行，使用方则无需再关注如何实现补偿方法，将柔性事务管理器的应用范畴成功的定位回了事务的本源——数据库层面。</description>
    </item>
    
    <item>
      <title>Saga柔性事务</title>
      <link>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/transaction/principle/base-transaction-saga/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/transaction/principle/base-transaction-saga/</guid>
      <description>实现原理 Saga柔性事务的实现类为SagaShardingTransactionMananger, ShardingSphere通过Hook的方式拦截逻辑SQL的解析和路由结果，这样，在分片物理SQL执行前，可以生成逆向SQL，在事务提交阶段再把SQL调用链交给Saga引擎处理。
1.Init（Saga引擎初始化） 包含Saga柔性事务的应用启动时，saga-actuator引擎会根据saga.properties的配置进行初始化的流程。
2.Begin（开启Saga全局事务） 每次开启Saga全局事务时，将会生成本次全局事务的上下文（SagaTransactionContext），事务上下文记录了所有子事务的正向SQL和逆向SQL，作为生成事务调用链的元数据使用。
3.执行物理SQL 在物理SQL执行前，ShardingSphere根据SQL的类型生成逆向SQL，这里是通过Hook的方式拦截Parser的解析结果进行实现。
4.Commit/rollback（提交Saga事务） 提交阶段会生成Saga执行引擎所需的调用链路图，commit操作产生ForwardRecovery（正向SQL补偿）任务，rollback操作产生BackwardRecovery任务（逆向SQL补偿）。</description>
    </item>
    
    <item>
      <title>Spring Boot配置</title>
      <link>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/manual/sharding-jdbc/configuration/config-spring-boot/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/manual/sharding-jdbc/configuration/config-spring-boot/</guid>
      <description>注意事项 行表达式标识符可以使用${...}或$-&amp;gt;{...}，但前者与Spring本身的属性文件占位符冲突，因此在Spring环境中使用行表达式标识符建议使用$-&amp;gt;{...}。
配置示例 数据分片 spring.shardingsphere.datasource.names=ds0,ds1 spring.shardingsphere.datasource.ds0.type=org.apache.commons.dbcp.BasicDataSource spring.shardingsphere.datasource.ds0.driver-class-name=com.mysql.jdbc.Driver spring.shardingsphere.datasource.ds0.url=jdbc:mysql://localhost:3306/ds0 spring.shardingsphere.datasource.ds0.username=root spring.shardingsphere.datasource.ds0.password= spring.shardingsphere.datasource.ds1.type=org.apache.commons.dbcp.BasicDataSource spring.shardingsphere.datasource.ds1.driver-class-name=com.mysql.jdbc.Driver spring.shardingsphere.datasource.ds1.url=jdbc:mysql://localhost:3306/ds1 spring.shardingsphere.datasource.ds1.username=root spring.shardingsphere.datasource.ds1.password= spring.shardingsphere.sharding.tables.t_order.actual-data-nodes=ds$-&amp;gt;{0..1}.t_order$-&amp;gt;{0..1} spring.shardingsphere.sharding.tables.t_order.table-strategy.inline.sharding-column=order_id spring.shardingsphere.sharding.tables.t_order.table-strategy.inline.algorithm-expression=t_order$-&amp;gt;{order_id % 2} spring.shardingsphere.sharding.tables.t_order.key-generator.column=order_id spring.shardingsphere.sharding.tables.t_order.key-generator.type=SNOWFLAKE spring.shardingsphere.sharding.tables.t_order_item.actual-data-nodes=ds$-&amp;gt;{0..1}.t_order_item$-&amp;gt;{0..1} spring.shardingsphere.sharding.tables.t_order_item.table-strategy.inline.sharding-column=order_id spring.shardingsphere.sharding.tables.t_order_item.table-strategy.inline.algorithm-expression=t_order_item$-&amp;gt;{order_id % 2} spring.shardingsphere.sharding.tables.t_order_item.key-generator.column=order_item_id spring.shardingsphere.sharding.tables.t_order_item.key-generator.type=SNOWFLAKE spring.shardingsphere.sharding.binding-tables=t_order,t_order_item spring.shardingsphere.sharding.broadcast-tables=t_config spring.shardingsphere.sharding.default-database-strategy.inline.sharding-column=user_id spring.shardingsphere.sharding.default-database-strategy.inline.algorithm-expression=ds$-&amp;gt;{user_id % 2}  读写分离 spring.shardingsphere.datasource.names=master,slave0,slave1 spring.shardingsphere.datasource.master.type=org.apache.commons.dbcp.BasicDataSource spring.shardingsphere.datasource.master.driver-class-name=com.mysql.jdbc.Driver spring.shardingsphere.datasource.master.url=jdbc:mysql://localhost:3306/master spring.shardingsphere.datasource.master.username=root spring.shardingsphere.datasource.master.password= spring.shardingsphere.datasource.slave0.type=org.apache.commons.dbcp.BasicDataSource spring.shardingsphere.datasource.slave0.driver-class-name=com.mysql.jdbc.Driver spring.shardingsphere.datasource.slave0.url=jdbc:mysql://localhost:3306/slave0 spring.shardingsphere.datasource.slave0.username=root spring.shardingsphere.datasource.slave0.password= spring.shardingsphere.datasource.slave1.type=org.apache.commons.dbcp.BasicDataSource spring.shardingsphere.datasource.slave1.driver-class-name=com.mysql.jdbc.Driver spring.shardingsphere.datasource.slave1.url=jdbc:mysql://localhost:3306/slave1 spring.shardingsphere.datasource.slave1.username=root spring.shardingsphere.datasource.slave1.password= spring.shardingsphere.masterslave.load-balance-algorithm-type=round_robin spring.shardingsphere.masterslave.name=ms spring.shardingsphere.masterslave.master-data-source-name=master spring.shardingsphere.masterslave.slave-data-source-names=slave0,slave1 spring.shardingsphere.props.sql.show=true  数据脱敏 spring.shardingsphere.datasource.name=ds spring.shardingsphere.datasource.ds.type=org.apache.commons.dbcp2.BasicDataSource spring.shardingsphere.datasource.ds.driver-class-name=com.mysql.jdbc.Driver spring.shardingsphere.datasource.ds.url=jdbc:mysql://127.0.0.1:3306/encrypt?serverTimezone=UTC&amp;amp;useSSL=false spring.shardingsphere.datasource.ds.username=root spring.shardingsphere.datasource.ds.password= spring.shardingsphere.datasource.ds.max-total=100 spring.shardingsphere.encrypt.encryptors.encryptor_aes.type=aes spring.shardingsphere.encrypt.encryptors.encryptor_aes.props.aes.key.value=123456 spring.</description>
    </item>
    
    <item>
      <title>不支持项</title>
      <link>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/read-write-split/unsupported-items/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/read-write-split/unsupported-items/</guid>
      <description> 主库和从库的数据同步。 主库和从库的数据同步延迟导致的数据不一致。 主库双写或多写。  </description>
    </item>
    
    <item>
      <title>强制分片路由</title>
      <link>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/sharding/other-features/sharding-hint/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/sharding/other-features/sharding-hint/</guid>
      <description>实现动机 通过解析SQL语句提取分片键列与值并进行分片是ShardingSphere对SQL零侵入的实现方式。若SQL语句中没有分片条件，则无法进行分片，需要全路由。
在一些应用场景中，分片条件并不存在于SQL，而存在于外部业务逻辑。因此需要提供一种通过外部指定分片结果的方式，在ShardingSphere中叫做Hint。
实现机制 ShardingSphere使用ThreadLocal管理分片键值。可以通过编程的方式向HintManager中添加分片条件，该分片条件仅在当前线程内生效。
除了通过编程的方式使用强制分片路由，ShardingSphere还计划通过SQL中的特殊注释的方式引用Hint，使开发者可以采用更加透明的方式使用该功能。
指定了强制分片路由的SQL将会无视原有的分片逻辑，直接路由至指定的真实数据节点。</description>
    </item>
    
    <item>
      <title>强制路由</title>
      <link>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/manual/sharding-jdbc/usage/hint/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/manual/sharding-jdbc/usage/hint/</guid>
      <description>简介 ShardingSphere使用ThreadLocal管理分片键值进行Hint强制路由。可以通过编程的方式向HintManager中添加分片值，该分片值仅在当前线程内生效。 Hint方式主要使用场景：
1.分片字段不存在SQL中、数据库表结构中，而存在于外部业务逻辑。
2.强制在主库进行某些数据操作。
基于暗示(Hint)的数据分片 配置Hint分片算法 Hint分片算法需要用户实现org.apache.shardingsphere.api.sharding.hint.HintShardingAlgorithm接口。ShardingSphere在进行Routing时，如果发现LogicTable的TableRule采用了 Hint的分片算法，将会从HintManager中获取分片值进行路由操作。
参考配置如下：
shardingRule: tables: t_order: actualDataNodes: demo_ds_${0..1}.t_order_${0..1} databaseStrategy: hint: algorithmClassName: org.apache.shardingsphere.userAlgo.HintAlgorithm tableStrategy: hint: algorithmClassName: org.apache.shardingsphere.userAlgo.HintAlgorithm defaultTableStrategy: none: defaultKeyGenerator: type: SNOWFLAKE column: order_id props: sql.show: true  获取HintManager HintManager hintManager = HintManager.getInstance();  添加分片键值  使用hintManager.addDatabaseShardingValue来添加数据源分片键值。 使用hintManager.addTableShardingValue来添加表分片键值。   分库不分表情况下，强制路由至某一个分库时，可使用hintManager.setDatabaseShardingValue方式添加分片。通过此方式添加分片键值后，将跳过SQL解析和改写阶段，从而提高整体执行效率。
 清除分片键值 分片键值保存在ThreadLocal中，所以需要在操作结束时调用hintManager.close()来清除ThreadLocal中的内容。
hintManager实现了AutoCloseable接口，可推荐使用try with resource自动关闭。
完整代码示例 // Sharding database and table with using hintManager. String sql = &amp;quot;SELECT * FROM t_order&amp;quot;; try (HintManager hintManager = HintManager.</description>
    </item>
    
    <item>
      <title>支持的注册中心</title>
      <link>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/orchestration/supported-registry-repo/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/orchestration/supported-registry-repo/</guid>
      <description>SPI Service Provider Interface (SPI)是一种为了被第三方实现或扩展的API。它可以用于实现框架扩展或组件替换。
ShardingSphere在数据库治理模块使用SPI方式载入注册中心，进行实例熔断和数据库禁用。 目前，ShardingSphere内部支持Zookeeper这种常用的注册中心。 此外，您可以使用其他第三方注册中心，并通过SPI的方式注入到ShardingSphere，从而使用该注册中心，实现数据库治理功能。
Zookeeper ShardingSphere官方使用Apache Curator作为Zookeeper的实现方案。 请使用Zookeeper 3.4.6及其以上版本，详情请参见官方网站。
Nacos ShardingSphere官方使用Nacos Client作为Nacos的实现方案。 请使用Nacos Client 1.0.0及其以上版本，详情请参见官方网站。
其他 使用SPI方式自行实现相关逻辑编码。</description>
    </item>
    
    <item>
      <title>改写引擎</title>
      <link>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/sharding/principle/rewrite/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/sharding/principle/rewrite/</guid>
      <description>工程师面向逻辑库与逻辑表书写的SQL，并不能够直接在真实的数据库中执行，SQL改写用于将逻辑SQL改写为在真实数据库中可以正确执行的SQL。 它包括正确性改写和优化改写两部分。
正确性改写 在包含分表的场景中，需要将分表配置中的逻辑表名称改写为路由之后所获取的真实表名称。仅分库则不需要表名称的改写。除此之外，还包括补列和分页信息修正等内容。
标识符改写 需要改写的标识符包括表名称、索引名称以及Schema名称。
表名称改写是指将找到逻辑表在原始SQL中的位置，并将其改写为真实表的过程。表名称改写是一个典型的需要对SQL进行解析的场景。 从一个最简单的例子开始，若逻辑SQL为：
SELECT order_id FROM t_order WHERE order_id=1;  假设该SQL配置分片键order_id，并且order_id=1的情况，将路由至分片表1。那么改写之后的SQL应该为：
SELECT order_id FROM t_order_1 WHERE order_id=1;  在这种最简单的SQL场景中，是否将SQL解析为抽象语法树似乎无关紧要，只要通过字符串查找和替换就可以达到SQL改写的效果。 但是下面的场景，就无法仅仅通过字符串的查找替换来正确的改写SQL了：
SELECT order_id FROM t_order WHERE order_id=1 AND remarks=&#39; t_order xxx&#39;;  正确改写的SQL应该是：
SELECT order_id FROM t_order_1 WHERE order_id=1 AND remarks=&#39; t_order xxx&#39;;  而非：
SELECT order_id FROM t_order_1 WHERE order_id=1 AND remarks=&#39; t_order_1 xxx&#39;;  由于表名之外可能含有表名称的类似字符，因此不能通过简单的字符串替换的方式去改写SQL。
下面再来看一个更加复杂的SQL改写场景：
SELECT t_order.order_id FROM t_order WHERE t_order.order_id=1 AND remarks=&#39; t_order xxx&#39;;  上面的SQL将表名作为字段的标识符，因此在SQL改写时需要一并修改：</description>
    </item>
    
    <item>
      <title>柔性事务-Saga</title>
      <link>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/transaction/function/base-transaction-saga/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/transaction/function/base-transaction-saga/</guid>
      <description> 功能  完全支持跨库事务 支持失败SQL重试及最大努力送达 支持反向SQL、自动生成更新快照以及自动补偿 默认使用关系型数据库进行快照及事务日志的持久化，支持使用SPI的方式加载其他类型的持久化  不支持项  暂不支持资源隔离 暂不支持服务宕机后，自动恢复提交中的commit和rollback  支持情况 ShardingSphere的柔性事务已通过第三方SPI实现Saga事务，Saga引擎使用Servicecomb-Saga。
注意  反向SQL需要主键，请确保在表结构中定义主键。 对于INSERT语句， 需要在SQL中显示插入主键值，如INSERT INTO ${table_name} (id, value, ...) VALUES (11111, &#39;&#39;, ....) (其中id为表主键)。 若需要自动生成主键，可使用ShardingSphere的分布式主键。  </description>
    </item>
    
    <item>
      <title>解析器</title>
      <link>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/sharding/use-norms/parser/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/sharding/use-norms/parser/</guid>
      <description>ShardingSphere使用不同解析器支持SQL多种方言。对于未实现解析器的特定SQL方言，默认采用SQL92标准进行解析。
特定SQL方言解析器  PostgreSQL解析器
 MySQL解析器
 Oracle解析器
 SQLServer解析器
  注：MySQL解析器支持的方言包括MySQL、H2和MariaDB。
默认SQL方言解析器 其他SQL方言，如SQLite、Sybase、DB2和Informix等，默认采用SQL92标准进行解析。</description>
    </item>
    
    <item>
      <title>配置</title>
      <link>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/sharding/concept/configuration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/sharding/concept/configuration/</guid>
      <description>分片规则 分片规则配置的总入口。包含数据源配置、表配置、绑定表配置以及读写分离配置等。
数据源配置 真实数据源列表。
表配置 逻辑表名称、数据节点与分表规则的配置。
数据节点配置 用于配置逻辑表与真实表的映射关系。可分为均匀分布和自定义分布两种形式。
 均匀分布  指数据表在每个数据源内呈现均匀分布的态势，例如：
db0 ├── t_order0 └── t_order1 db1 ├── t_order0 └── t_order1  那么数据节点的配置如下：
db0.t_order0, db0.t_order1, db1.t_order0, db1.t_order1   自定义分布  指数据表呈现有特定规则的分布，例如：
db0 ├── t_order0 └── t_order1 db1 ├── t_order2 ├── t_order3 └── t_order4  那么数据节点的配置如下：
db0.t_order0, db0.t_order1, db1.t_order2, db1.t_order3, db1.t_order4  分片策略配置 对于分片策略存有数据源分片策略和表分片策略两种维度。
 数据源分片策略  对应于DatabaseShardingStrategy。用于配置数据被分配的目标数据源。
 表分片策略  对应于TableShardingStrategy。用于配置数据被分配的目标表，该目标表存在与该数据的目标数据源内。故表分片策略是依赖与数据源分片策略的结果的。
两种策略的API完全相同。
自增主键生成策略 通过在客户端生成自增主键替换以数据库原生自增主键的方式，做到分布式主键无重复。</description>
    </item>
    
    <item>
      <title>SQL改写测试引擎</title>
      <link>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/test-engine/rewrite-test-engine/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/test-engine/rewrite-test-engine/</guid>
      <description>目标 面向逻辑库与逻辑表书写的SQL，并不能够直接在真实的数据库中执行，SQL改写用于将逻辑SQL改写为在真实数据库中可以正确执行的SQL。 它包括正确性改写和优化改写两部分，所以 SQL 改写的测试都是基于这些改写方向进行校验的。
测试 SQL 改写测试用例位于 sharding-core/sharding-core-rewrite 下的 test 中。SQL 改写的测试主要依赖如下几个部分：
 测试引擎 环境配置 验证数据  测试引擎是 SQL 改写测试的入口，跟其他引擎一样，通过 Junit 的 Parameterized 逐条读取 test\resources 目录中测试类型下对应的 xml 文件，然后按读取顺序一一进行验证。
环境配置存放在 test\resources\yaml 路径中测试类型下对应的 yaml 中。配置了dataSources，shardingRule，encryptRule 等信息，例子如下：
dataSources: db: !!com.zaxxer.hikari.HikariDataSource driverClassName: org.h2.Driver jdbcUrl: jdbc:h2:mem:db;DB_CLOSE_DELAY=-1;DATABASE_TO_UPPER=false;MODE=MYSQL username: sa password: ## sharding 规则 shardingRule: tables: t_account: actualDataNodes: db.t_account_${0..1} tableStrategy: inline: shardingColumn: account_id algorithmExpression: t_account_${account_id % 2} keyGenerator: type: TEST column: account_id t_account_detail: actualDataNodes: db.t_account_detail_${0..1} tableStrategy: inline: shardingColumn: order_id algorithmExpression: t_account_detail_${account_id % 2} bindingTables: - t_account, t_account_detail  验证数据存放在 test\resources 路径中测试类型下对应的 xml 文件中。验证数据中， yaml-rule 指定了环境以及 rule 的配置文件，input 指定了待测试的 SQL 以及参数，output 指定了期待的 SQL 以及参数。 其中 db-type 决定了 SQL 解析的类型，默认为 SQL92, 例如：</description>
    </item>
    
    <item>
      <title>Seata柔性事务</title>
      <link>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/transaction/concept/base-transaction-seata/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/transaction/concept/base-transaction-seata/</guid>
      <description>Seata柔性事务 Seata是阿里集团和蚂蚁金服联合打造的分布式事务框架，截止到0.5.x版本包含了AT事务和TCC事务。其中AT事务的目标是在微服务架构下，提供增量的事务ACID语意，让用户像使用本地事务一样，使用分布式事务，核心理念同ShardingSphere一脉相承。
Seata AT事务模型 Seata AT事务模型包含TM(事务管理器)，RM(资源管理器)，TC(事务协调器)。其中TC是一个独立的服务需要单独部署，TM和RM以jar包的方式同业务应用部署在一起，它们同TC建立长连接，在整个事务生命周期内，保持RPC通信。 其中全局事务的发起方作为TM，全局事务的参与者作为RM ; TM负责全局事务的begin和commit/rollback，RM负责分支事务的执行结果上报，并且通过TC的协调进行commit/rollback。</description>
    </item>
    
    <item>
      <title>Seata柔性事务</title>
      <link>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/transaction/principle/base-transaction-seata/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/transaction/principle/base-transaction-seata/</guid>
      <description>实现原理 整合Seata AT事务时，需要把TM，RM，TC的模型融入到ShardingSphere 分布式事务的SPI的生态中。在数据库资源上，Seata通过对接DataSource接口，让JDBC操作可以同TC进行RPC通信。同样，ShardingSphere也是面向DataSource接口对用户配置的物理DataSource进行了聚合，因此把物理DataSource二次包装为Seata 的DataSource后，就可以把Seata AT事务融入到ShardingSphere的分片中。
1.Init（Seata引擎初始化） 包含Seata柔性事务的应用启动时，用户配置的数据源会按seata.conf的配置，适配为Seata事务所需的DataSourceProxy，并且注册到RM中。
2.Begin（开启Seata全局事务） TM控制全局事务的边界，TM通过向TC发送Begin指令，获取全局事务ID，所有分支事务通过此全局事务ID，参与到全局事务中；全局事务ID的上下文存放在当前线程变量中。
3.执行分片物理SQL 处于Seata全局事务中的分片SQL通过RM生成undo快照，并且发送participate指令到TC，加入到全局事务中。ShardingSphere的分片物理SQL是按多线程方式执行，因此整合Seata AT事务时，需要在主线程和子线程间进行全局事务ID的上下文传递，这同服务间的上下文传递思路完全相同。
4.Commit/rollback（提交Seata事务） 提交Seata事务时，TM会向TC发送全局事务的commit和rollback指令，TC根据全局事务ID协调所有分支事务进行commit和rollback。</description>
    </item>
    
    <item>
      <title>Spring命名空间配置</title>
      <link>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/manual/sharding-jdbc/configuration/config-spring-namespace/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/manual/sharding-jdbc/configuration/config-spring-namespace/</guid>
      <description>注意事项 行表达式标识符可以使用${...}或$-&amp;gt;{...}，但前者与Spring本身的属性文件占位符冲突，因此在Spring环境中使用行表达式标识符建议使用$-&amp;gt;{...}。
配置示例 详细example: shardingsphere-example
数据分片 &amp;lt;?xml version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;UTF-8&amp;quot;?&amp;gt; &amp;lt;beans xmlns=&amp;quot;http://www.springframework.org/schema/beans&amp;quot; xmlns:xsi=&amp;quot;http://www.w3.org/2001/XMLSchema-instance&amp;quot; xmlns:p=&amp;quot;http://www.springframework.org/schema/p&amp;quot; xmlns:context=&amp;quot;http://www.springframework.org/schema/context&amp;quot; xmlns:tx=&amp;quot;http://www.springframework.org/schema/tx&amp;quot; xmlns:sharding=&amp;quot;http://shardingsphere.apache.org/schema/shardingsphere/sharding&amp;quot; xsi:schemaLocation=&amp;quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://shardingsphere.apache.org/schema/shardingsphere/sharding http://shardingsphere.apache.org/schema/shardingsphere/sharding/sharding.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd&amp;quot;&amp;gt; &amp;lt;context:annotation-config /&amp;gt; &amp;lt;bean id=&amp;quot;entityManagerFactory&amp;quot; class=&amp;quot;org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean&amp;quot;&amp;gt; &amp;lt;property name=&amp;quot;dataSource&amp;quot; ref=&amp;quot;shardingDataSource&amp;quot; /&amp;gt; &amp;lt;property name=&amp;quot;jpaVendorAdapter&amp;quot;&amp;gt; &amp;lt;bean class=&amp;quot;org.springframework.orm.jpa.vendor.HibernateJpaVendorAdapter&amp;quot; p:database=&amp;quot;MYSQL&amp;quot; /&amp;gt; &amp;lt;/property&amp;gt; &amp;lt;property name=&amp;quot;packagesToScan&amp;quot; value=&amp;quot;org.apache.shardingsphere.example.core.jpa.entity&amp;quot; /&amp;gt; &amp;lt;property name=&amp;quot;jpaProperties&amp;quot;&amp;gt; &amp;lt;props&amp;gt; &amp;lt;prop key=&amp;quot;hibernate.dialect&amp;quot;&amp;gt;org.hibernate.dialect.MySQLDialect&amp;lt;/prop&amp;gt; &amp;lt;prop key=&amp;quot;hibernate.hbm2ddl.auto&amp;quot;&amp;gt;create&amp;lt;/prop&amp;gt; &amp;lt;prop key=&amp;quot;hibernate.show_sql&amp;quot;&amp;gt;true&amp;lt;/prop&amp;gt; &amp;lt;/props&amp;gt; &amp;lt;/property&amp;gt; &amp;lt;/bean&amp;gt; &amp;lt;bean id=&amp;quot;transactionManager&amp;quot; class=&amp;quot;org.springframework.orm.jpa.JpaTransactionManager&amp;quot; p:entityManagerFactory-ref=&amp;quot;entityManagerFactory&amp;quot; /&amp;gt; &amp;lt;tx:annotation-driven /&amp;gt; &amp;lt;bean id=&amp;quot;ds0&amp;quot; class=&amp;quot;org.apache.commons.dbcp.BasicDataSource&amp;quot; destroy-method=&amp;quot;close&amp;quot;&amp;gt; &amp;lt;property name=&amp;quot;driverClassName&amp;quot; value=&amp;quot;com.</description>
    </item>
    
    <item>
      <title>应用性能监控</title>
      <link>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/orchestration/apm/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/orchestration/apm/</guid>
      <description>背景 APM是应用性能监控的缩写。目前APM的主要功能着眼于分布式系统的性能诊断，其主要功能包括调用链展示，应用拓扑分析等。
ShardingSphere并不负责如何采集、存储以及展示应用性能监控的相关数据，而是将SQL解析与SQL执行这两块数据分片的最核心的相关信息发送至应用性能监控系统，并交由其处理。 换句话说，ShardingSphere仅负责产生具有价值的数据，并通过标准协议递交至相关系统。ShardingSphere可以通过两种方式对接应用性能监控系统。
第一种方式是使用OpenTracing API发送性能追踪数据。面向OpenTracing协议的APM产品都可以和ShardingSphere自动对接，比如SkyWalking，Zipkin和Jaeger。使用这种方式只需要在启动时配置OpenTracing协议的实现者即可。 它的优点是可以兼容所有的与OpenTracing协议兼容的产品作为APM的展现系统，如果采用公司愿意实现自己的APM系统，也只需要实现OpenTracing协议，即可自动展示ShardingSphere的链路追踪信息。 缺点是OpenTracing协议发展并不稳定，较新的版本实现者较少，且协议本身过于中立，对于个性化的相关产品的实现不如原生支持强大。
第二种方式是使用SkyWalking的自动探针。 ShardingSphere团队与SkyWalking团队共同合作，在SkyWalking中实现了ShardingSphere自动探针，可以将相关的应用性能数据自动发送到SkyWalking中。
使用方法 使用OpenTracing协议  方法1：通过读取系统参数注入APM系统提供的Tracer实现类  启动时添加参数
 -Dorg.apache.shardingsphere.opentracing.tracer.class=org.apache.skywalking.apm.toolkit.opentracing.SkywalkingTracer  调用初始化方法
ShardingTracer.init();   方法2：通过参数注入APM系统提供的Tracer实现类  ShardingTracer.init(new SkywalkingTracer());  注意:使用SkyWalking的OpenTracing探针时，应将原ShardingSphere探针插件禁用，以防止两种插件互相冲突
使用SkyWalking自动探针 请参考SkyWalking部署手册。
效果展示 无论使用哪种方式，都可以方便的将APM信息展示在对接的系统中，以下以SkyWalking为例。
应用架构 使用Sharding-Proxy访问两个数据库192.168.0.1:3306和192.168.0.2:3306，且每个数据库中有两个分表。
拓扑图展示 从图中看，用户访问18次Sharding-Proxy应用，每次每个数据库访问了两次。这是由于每次访问涉及到每个库中的两个分表，所以每次访问了四张表。
跟踪数据展示 从跟踪图中可以能够看到SQL解析和执行的情况。
/Sharding-Sphere/parseSQL/ : 表示本次SQL的解析性能。
/Sharding-Sphere/executeSQL/ : 表示具体执行的实际SQL的性能。
异常情况展示 从跟踪图中可以能够看到发生异常的节点。
/Sharding-Sphere/executeSQL/ : 表示执行SQL异常的结果。
/Sharding-Sphere/executeSQL/ : 表示执行SQL异常的日志。</description>
    </item>
    
    <item>
      <title>性能测试报告</title>
      <link>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/manual/sharding-jdbc/stress-test/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/manual/sharding-jdbc/stress-test/</guid>
      <description>测试结果概述  性能损耗测试：服务器资源充足、并发数相同，比较JDBC和Sharding-JDBC性能损耗，Sharding-JDBC相对JDBC损耗不超过7%。 性能对比测试：服务器资源使用到极限，相同的场景JDBC与Sharding-JDBC的吞吐量相当。 性能对比测试：服务器资源使用到极限，Sharding-JDBC采用分库分表后，Sharding-JDBC吞吐量较JDBC不分表有接近2倍的提升。 性能对比测试：服务器资源使用到极限，Sharding-JDBC V1.5.2与V1.4.2对比，性能比较稳定。  基准测试性能对比    业务场景 JDBC Sharding-JDBC1.5.2 Sharding-JDBC1.5.2/JDBC损耗     单库单表查询 493 470 4.7%   单库单表更新 6682 6303 5.7%   单库单表插入 6855 6375 7%    JDBC单库两表与Sharding-JDBC两库各两表对比    业务场景 JDBC单库两表 Sharding-JDBC两库各两表 性能提升至     查询 1736 3331 192%   更新 9170 17997 196%   插入 11574 23043 199%    JDBC单库单表与Sharding-JDBC两库各一表对比    业务场景 JDBC单库单表 Sharding-JDBC两库各一表 性能提升至     查询 1586 2944 185%   更新 9548 18561 194%   插入 11182 21414 192%    Sharding-JDBC v1.</description>
    </item>
    
    <item>
      <title>执行引擎</title>
      <link>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/sharding/principle/execute/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/sharding/principle/execute/</guid>
      <description>ShardingSphere采用一套自动化的执行引擎，负责将路由和改写完成之后的真实SQL安全且高效发送到底层数据源执行。 它不是简单地将SQL通过JDBC直接发送至数据源执行；也并非直接将执行请求放入线程池去并发执行。它更关注平衡数据源连接创建以及内存占用所产生的消耗，以及最大限度地合理利用并发等问题。 执行引擎的目标是自动化的平衡资源控制与执行效率。
连接模式 从资源控制的角度看，业务方访问数据库的连接数量应当有所限制。 它能够有效地防止某一业务操作过多的占用资源，从而将数据库连接的资源耗尽，以致于影响其他业务的正常访问。 特别是在一个数据库实例中存在较多分表的情况下，一条不包含分片键的逻辑SQL将产生落在同库不同表的大量真实SQL，如果每条真实SQL都占用一个独立的连接，那么一次查询无疑将会占用过多的资源。
从执行效率的角度看，为每个分片查询维持一个独立的数据库连接，可以更加有效的利用多线程来提升执行效率。 为每个数据库连接开启独立的线程，可以将I/O所产生的消耗并行处理。为每个分片维持一个独立的数据库连接，还能够避免过早的将查询结果数据加载至内存。 独立的数据库连接，能够持有查询结果集游标位置的引用，在需要获取相应数据时移动游标即可。
以结果集游标下移进行结果归并的方式，称之为流式归并，它无需将结果数据全数加载至内存，可以有效的节省内存资源，进而减少垃圾回收的频次。 当无法保证每个分片查询持有一个独立数据库连接时，则需要在复用该数据库连接获取下一张分表的查询结果集之前，将当前的查询结果集全数加载至内存。 因此，即使可以采用流式归并，在此场景下也将退化为内存归并。
一方面是对数据库连接资源的控制保护，一方面是采用更优的归并模式达到对中间件内存资源的节省，如何处理好两者之间的关系，是ShardingSphere执行引擎需求解决的问题。 具体来说，如果一条SQL在经过ShardingSphere的分片后，需要操作某数据库实例下的200张表。 那么，是选择创建200个连接并行执行，还是选择创建一个连接串行执行呢？效率与资源控制又应该如何抉择呢？
针对上述场景，ShardingSphere提供了一种解决思路。 它提出了连接模式（Connection Mode）的概念，将其划分为内存限制模式（MEMORY_STRICTLY）和连接限制模式（CONNECTION_STRICTLY）这两种类型。
内存限制模式 使用此模式的前提是，ShardingSphere对一次操作所耗费的数据库连接数量不做限制。 如果实际执行的SQL需要对某数据库实例中的200张表做操作，则对每张表创建一个新的数据库连接，并通过多线程的方式并发处理，以达成执行效率最大化。 并且在SQL满足条件情况下，优先选择流式归并，以防止出现内存溢出或避免频繁垃圾回收情况。
连接限制模式 使用此模式的前提是，ShardingSphere严格控制对一次操作所耗费的数据库连接数量。 如果实际执行的SQL需要对某数据库实例中的200张表做操作，那么只会创建唯一的数据库连接，并对其200张表串行处理。 如果一次操作中的分片散落在不同的数据库，仍然采用多线程处理对不同库的操作，但每个库的每次操作仍然只创建一个唯一的数据库连接。 这样即可以防止对一次请求对数据库连接占用过多所带来的问题。该模式始终选择内存归并。
内存限制模式适用于OLAP操作，可以通过放宽对数据库连接的限制提升系统吞吐量； 连接限制模式适用于OLTP操作，OLTP通常带有分片键，会路由到单一的分片，因此严格控制数据库连接，以保证在线系统数据库资源能够被更多的应用所使用，是明智的选择。
自动化执行引擎 ShardingSphere最初将使用何种模式的决定权交由用户配置，让开发者依据自己业务的实际场景需求选择使用内存限制模式或连接限制模式。
这种解决方案将两难的选择的决定权交由用户，使得用户必须要了解这两种模式的利弊，并依据业务场景需求进行选择。 这无疑增加了用户对ShardingSphere的学习和使用的成本，并非最优方案。
这种一分为二的处理方案，将两种模式的切换交由静态的初始化配置，是缺乏灵活应对能力的。在实际的使用场景中，面对不同SQL以及占位符参数，每次的路由结果是不同的。 这就意味着某些操作可能需要使用内存归并，而某些操作则可能选择流式归并更优，具体采用哪种方式不应该由用户在ShardingSphere启动之前配置好，而是应该根据SQL和占位符参数的场景，来动态的决定连接模式。
为了降低用户的使用成本以及连接模式动态化这两个问题，ShardingSphere提炼出自动化执行引擎的思路，在其内部消化了连接模式概念。 用户无需了解所谓的内存限制模式和连接限制模式是什么，而是交由执行引擎根据当前场景自动选择最优的执行方案。
自动化执行引擎将连接模式的选择粒度细化至每一次SQL的操作。 针对每次SQL请求，自动化执行引擎都将根据其路由结果，进行实时的演算和权衡，并自主地采用恰当的连接模式执行，以达到资源控制和效率的最优平衡。 针对自动化的执行引擎，用户只需配置maxConnectionSizePerQuery即可，该参数表示一次查询时每个数据库所允许使用的最大连接数。
执行引擎分为准备和执行两个阶段。
准备阶段 顾名思义，此阶段用于准备执行的数据。它分为结果集分组和执行单元创建两个步骤。
结果集分组是实现内化连接模式概念的关键。执行引擎根据maxConnectionSizePerQuery配置项，结合当前路由结果，选择恰当的连接模式。 具体步骤如下：
 将SQL的路由结果按照数据源的名称进行分组。
 通过下图的公式，可以获得每个数据库实例在maxConnectionSizePerQuery的允许范围内，每个连接需要执行的SQL路由结果组，并计算出本次请求的最优连接模式。
  在maxConnectionSizePerQuery允许的范围内，当一个连接需要执行的请求数量大于1时，意味着当前的数据库连接无法持有相应的数据结果集，则必须采用内存归并； 反之，当一个连接需要执行的请求数量等于1时，意味着当前的数据库连接可以持有相应的数据结果集，则可以采用流式归并。
每一次的连接模式的选择，是针对每一个物理数据库的。也就是说，在同一次查询中，如果路由至一个以上的数据库，每个数据库的连接模式不一定一样，它们可能是混合存在的形态。
通过上一步骤获得的路由分组结果创建执行的单元。 当数据源使用数据库连接池等控制数据库连接数量的技术时，在获取数据库连接时，如果不妥善处理并发，则有一定几率发生死锁。 在多个请求相互等待对方释放数据库连接资源时，将会产生饥饿等待，造成交叉的死锁问题。
举例说明，假设一次查询需要在某一数据源上获取两个数据库连接，并路由至同一个数据库的两个分表查询。 则有可能出现查询A已获取到该数据源的1个数据库连接，并等待获取另一个数据库连接；而查询B也已经在该数据源上获取到的一个数据库连接，并同样等待另一个数据库连接的获取。 如果数据库连接池的允许最大连接数是2，那么这2个查询请求将永久的等待下去。下图描绘了死锁的情况。
ShardingSphere为了避免死锁的出现，在获取数据库连接时进行了同步处理。 它在创建执行单元时，以原子性的方式一次性获取本次SQL请求所需的全部数据库连接，杜绝了每次查询请求获取到部分资源的可能。 由于对数据库的操作非常频繁，每次获取数据库连接时时都进行锁定，会降低ShardingSphere的并发。因此，ShardingSphere在这里进行了2点优化：
 避免锁定一次性只需要获取1个数据库连接的操作。因为每次仅需要获取1个连接，则不会发生两个请求相互等待的场景，无需锁定。 对于大部分OLTP的操作，都是使用分片键路由至唯一的数据节点，这会使得系统变为完全无锁的状态，进一步提升了并发效率。 除了路由至单分片的情况，读写分离也在此范畴之内。
 仅针对内存限制模式时才进行资源锁定。在使用连接限制模式时，所有的查询结果集将在装载至内存之后释放掉数据库连接资源，因此不会产生死锁等待的问题。</description>
    </item>
    
    <item>
      <title>柔性事务-Seata</title>
      <link>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/transaction/function/base-transaction-seata/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/transaction/function/base-transaction-seata/</guid>
      <description> 功能  完全支持跨库分布式事务 支持RC隔离级别 通过undo快照进行事务回滚 支持服务宕机后的，自动恢复提交中的事务  依赖  需要额外部署Seata-server服务进行分支事务的协调  待优化项  ShardingSphere和Seata会对SQL进行重复解析  </description>
    </item>
    
    <item>
      <title>编排治理</title>
      <link>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/manual/sharding-jdbc/usage/orchestration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/manual/sharding-jdbc/usage/orchestration/</guid>
      <description>使用治理功能需要指定一个注册中心。配置将全部存入注册中心，可以在每次启动时使用本地配置覆盖注册中心配置，也可以只通过注册中心读取配置。
不使用Spring 引入Maven依赖 &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.apache.shardingsphere&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;sharding-jdbc-orchestration&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;${sharding-sphere.version}&amp;lt;/version&amp;gt; &amp;lt;/dependency&amp;gt; &amp;lt;!--若使用zookeeper, 请加入下面Maven坐标--&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.apache.shardingsphere&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;sharding-orchestration-reg-zookeeper-curator&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;${sharding-sphere.version}&amp;lt;/version&amp;gt; &amp;lt;/dependency&amp;gt;  基于Java编码的规则配置 // 省略配置dataSourceMap以及shardingRuleConfig // ... // 配置注册中心 RegistryCenterConfiguration regConfig = new RegistryCenterConfiguration(&amp;quot;zookeeper&amp;quot;); regConfig.setServerLists(&amp;quot;localhost:2181&amp;quot;); regConfig.setNamespace(&amp;quot;sharding-sphere-orchestration&amp;quot;); // 配置治理 OrchestrationConfiguration orchConfig = new OrchestrationConfiguration(&amp;quot;orchestration-sharding-data-source&amp;quot;, regConfig, false); // 获取数据源对象 DataSource dataSource = OrchestrationShardingDataSourceFactory.createDataSource(dataSourceMap, shardingRuleConfig, new Properties(), orchConfig);  基于Yaml的规则配置 或通过Yaml方式配置，与以上配置等价：
orchestration: name: orchestration-sharding-data-source overwrite: false registry: type: zookeeper serverLists: localhost:2181 namespace: sharding-sphere-orchestration  DataSource dataSource = YamlOrchestrationShardingDataSourceFactory.createDataSource(yamlFile);  使用Spring 引入Maven依赖 &amp;lt;!</description>
    </item>
    
    <item>
      <title>分布式事务</title>
      <link>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/manual/sharding-jdbc/usage/transaction/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/manual/sharding-jdbc/usage/transaction/</guid>
      <description>ShardingDataSource已经整合了分布式事务的功能，因此不需要用户进行额外的配置，每次获取ShardingConnection前，通过修改TransactionTypeHolder，可以对事务类型进行切换。
XA事务 引入Maven依赖 &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.apache.shardingsphere&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;sharding-transaction-xa-core&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;${shardingsphere.version}&amp;lt;/version&amp;gt; &amp;lt;/dependency&amp;gt;  JAVA编码方式设置事务类型 TransactionTypeHolder.set(TransactionType.XA);  XA事务管理器参数配置（可选） ShardingSphere默认的XA事务管理器为Atomikos，在项目的logs目录中会生成xa_tx.log, 这是XA崩溃恢复时所需的日志，请勿删除。
也可以通过在项目的classpath中添加jta.properties来定制化Atomikos配置项。具体的配置规则请参考Atomikos的官方文档。
BASE（柔性）事务 ShardingSphere中已经整合了Saga和Seata两种BASE类型的事务
引入Maven依赖 &amp;lt;!-- saga柔性事务 --&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;io.shardingsphere&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;sharding-transaction-base-saga&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;${shardingsphere-spi-impl.version}&amp;lt;/version&amp;gt; &amp;lt;/dependency&amp;gt;  ${shardingsphere-spi-impl.version} 的jar暂未发布到maven中央仓，因此需要您根据源码自行部署。项目地址: shardingsphere-spi-impl
&amp;lt;!-- seata柔性事务 --&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.apache.shardingsphere&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;sharding-transaction-base-seata-at&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;${sharding-sphere.version}&amp;lt;/version&amp;gt; &amp;lt;/dependency&amp;gt;  JAVA编码方式设置事务类型 TransactionTypeHolder.set(TransactionType.BASE);  Saga配置 可以通过在项目的classpath中添加saga.properties来定制化Saga事务的配置项。当saga.persistence.enabled=true时，事务日志默认按JDBC的方式持久化到数据库中，也可以通过实现io.shardingsphere.transaction.saga.persistence.SagaPersistence SPI，支持定制化存储，具体可参考项目sharding-transaction-base-saga-persistence-jpa。
配置项的属性及说明如下：
   属性名称 默认值 说明     saga.actuator.executor.size 5 使用的线程池大小   saga.actuator.transaction.max.retries 5 失败SQL的最大重试次数   saga.actuator.compensation.max.retries 5 失败SQL的最大尝试补偿次数   saga.</description>
    </item>
    
    <item>
      <title>归并引擎</title>
      <link>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/sharding/principle/merge/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/sharding/principle/merge/</guid>
      <description>将从各个数据节点获取的多数据结果集，组合成为一个结果集并正确的返回至请求客户端，称为结果归并。
ShardingSphere支持的结果归并从功能上分为遍历、排序、分组、分页和聚合5种类型，它们是组合而非互斥的关系。 从结构划分，可分为流式归并、内存归并和装饰者归并。流式归并和内存归并是互斥的，装饰者归并可以在流式归并和内存归并之上做进一步的处理。
由于从数据库中返回的结果集是逐条返回的，并不需要将所有的数据一次性加载至内存中，因此，在进行结果归并时，沿用数据库返回结果集的方式进行归并，能够极大减少内存的消耗，是归并方式的优先选择。
流式归并是指每一次从结果集中获取到的数据，都能够通过逐条获取的方式返回正确的单条数据，它与数据库原生的返回结果集的方式最为契合。遍历、排序以及流式分组都属于流式归并的一种。
内存归并则是需要将结果集的所有数据都遍历并存储在内存中，再通过统一的分组、排序以及聚合等计算之后，再将其封装成为逐条访问的数据结果集返回。
装饰者归并是对所有的结果集归并进行统一的功能增强，目前装饰者归并有分页归并和聚合归并这2种类型。
遍历归并 它是最为简单的归并方式。 只需将多个数据结果集合并为一个单向链表即可。在遍历完成链表中当前数据结果集之后，将链表元素后移一位，继续遍历下一个数据结果集即可。
排序归并 由于在SQL中存在ORDER BY语句，因此每个数据结果集自身是有序的，因此只需要将数据结果集当前游标指向的数据值进行排序即可。 这相当于对多个有序的数组进行排序，归并排序是最适合此场景的排序算法。
ShardingSphere在对排序的查询进行归并时，将每个结果集的当前数据值进行比较（通过实现Java的Comparable接口完成），并将其放入优先级队列。 每次获取下一条数据时，只需将队列顶端结果集的游标下移，并根据新游标重新进入优先级排序队列找到自己的位置即可。
通过一个例子来说明ShardingSphere的排序归并，下图是一个通过分数进行排序的示例图。 图中展示了3张表返回的数据结果集，每个数据结果集已经根据分数排序完毕，但是3个数据结果集之间是无序的。 将3个数据结果集的当前游标指向的数据值进行排序，并放入优先级队列，t_score_0的第一个数据值最大，t_score_2的第一个数据值次之，t_score_1的第一个数据值最小，因此优先级队列根据t_score_0，t_score_2和t_score_1的方式排序队列。
下图则展现了进行next调用的时候，排序归并是如何进行的。 通过图中我们可以看到，当进行第一次next调用时，排在队列首位的t_score_0将会被弹出队列，并且将当前游标指向的数据值（也就是100）返回至查询客户端，并且将游标下移一位之后，重新放入优先级队列。 而优先级队列也会根据t_score_0的当前数据结果集指向游标的数据值（这里是90）进行排序，根据当前数值，t_score_0排列在队列的最后一位。 之前队列中排名第二的t_score_2的数据结果集则自动排在了队列首位。
在进行第二次next时，只需要将目前排列在队列首位的t_score_2弹出队列，并且将其数据结果集游标指向的值返回至客户端，并下移游标，继续加入队列排队，以此类推。 当一个结果集中已经没有数据了，则无需再次加入队列。
可以看到，对于每个数据结果集中的数据有序，而多数据结果集整体无序的情况下，ShardingSphere无需将所有的数据都加载至内存即可排序。 它使用的是流式归并的方式，每次next仅获取唯一正确的一条数据，极大的节省了内存的消耗。
从另一个角度来说，ShardingSphere的排序归并，是在维护数据结果集的纵轴和横轴这两个维度的有序性。 纵轴是指每个数据结果集本身，它是天然有序的，它通过包含ORDER BY的SQL所获取。 横轴是指每个数据结果集当前游标所指向的值，它需要通过优先级队列来维护其正确顺序。 每一次数据结果集当前游标的下移，都需要将该数据结果集重新放入优先级队列排序，而只有排列在队列首位的数据结果集才可能发生游标下移的操作。
分组归并 分组归并的情况最为复杂，它分为流式分组归并和内存分组归并。 流式分组归并要求SQL的排序项与分组项的字段以及排序类型（ASC或DESC）必须保持一致，否则只能通过内存归并才能保证其数据的正确性。
举例说明，假设根据科目分片，表结构中包含考生的姓名（为了简单起见，不考虑重名的情况）和分数。通过SQL获取每位考生的总分，可通过如下SQL：
SELECT name, SUM(score) FROM t_score GROUP BY name ORDER BY name;  在分组项与排序项完全一致的情况下，取得的数据是连续的，分组所需的数据全数存在于各个数据结果集的当前游标所指向的数据值，因此可以采用流式归并。如下图所示。
进行归并时，逻辑与排序归并类似。 下图展现了进行next调用的时候，流式分组归并是如何进行的。
通过图中我们可以看到，当进行第一次next调用时，排在队列首位的t_score_java将会被弹出队列，并且将分组值同为“Jetty”的其他结果集中的数据一同弹出队列。 在获取了所有的姓名为“Jetty”的同学的分数之后，进行累加操作，那么，在第一次next调用结束后，取出的结果集是“Jetty”的分数总和。 与此同时，所有的数据结果集中的游标都将下移至数据值“Jetty”的下一个不同的数据值，并且根据数据结果集当前游标指向的值进行重排序。 因此，包含名字顺着第二位的“John”的相关数据结果集则排在的队列的前列。
流式分组归并与排序归并的区别仅仅在于两点：
 它会一次性的将多个数据结果集中的分组项相同的数据全数取出。 它需要根据聚合函数的类型进行聚合计算。  对于分组项与排序项不一致的情况，由于需要获取分组的相关的数据值并非连续的，因此无法使用流式归并，需要将所有的结果集数据加载至内存中进行分组和聚合。 例如，若通过以下SQL获取每位考生的总分并按照分数从高至低排序：
SELECT name, SUM(score) FROM t_score GROUP BY name ORDER BY score DESC;  那么各个数据结果集中取出的数据与排序归并那张图的上半部分的表结构的原始数据一致，是无法进行流式归并的。</description>
    </item>
    
    <item>
      <title>性能测试</title>
      <link>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/test-engine/performance-test/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/test-engine/performance-test/</guid>
      <description>目标 对Sharding-JDBC，Sharding-Proxy及MySQL进行性能对比。从业务角度考虑，在基本应用场景（单路由，主从+脱敏+分库分表，全路由）下，INSERT+UPDATE+DELETE通常用作一个完整的关联操作，用于性能评估，而SELECT关注分片优化可用作性能评估的另一个操作；而主从模式下，可将INSERT+SELECT+DELETE作为一组评估性能的关联操作。为了更好的观察效果，设计在一定数据量的基础上，20并发线程持续压测半小时，进行增删改查性能测试。
测试场景 单路由 在1000数据量的基础上分库分表，根据id分为4个库，根据k分为1024个表，查询操作路由到单库单表。
主从 基本主从场景，设置一主库一从库，在10000数据量的基础上，观察读写性能。
主从+脱敏+分库分表 在1000数据量的基础上，根据id分为4个库，根据k分为1024个表，c使用aes加密，pad使用md5加密，查询操作路由到单库单表。
全路由 在1000数据量的基础上，分库分表，根据id分为4个库，根据k分为1个表，查询操作使用全路由。
测试环境搭建 数据库表结构 此处表结构参考sysbench的sbtest表
CREATE TABLE `tbl` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `k` int(11) NOT NULL DEFAULT 0, `c` char(120) NOT NULL DEFAULT &#39;&#39;, `pad` char(60) NOT NULL DEFAULT &#39;&#39;, PRIMARY KEY (`id`) );  测试场景配置 Sharding-JDBC使用与Sharding-Proxy一致的配置，MySQL直连一个库用作性能对比，下面为四个场景的具体配置：
单路由配置 schemaName: sharding_db dataSources: ds_0: url: jdbc:mysql://***.***.***.***:****/ds?serverTimezone=UTC&amp;amp;useSSL=false username: test password: connectionTimeoutMilliseconds: 30000 idleTimeoutMilliseconds: 60000 maxLifetimeMilliseconds: 1800000 maxPoolSize: 200 ds_1: url: jdbc:mysql://***.***.***.***:****/ds?serverTimezone=UTC&amp;amp;useSSL=false username: test password: connectionTimeoutMilliseconds: 30000 idleTimeoutMilliseconds: 60000 maxLifetimeMilliseconds: 1800000 maxPoolSize: 200 ds_2: url: jdbc:mysql://***.</description>
    </item>
    
    <item>
      <title>数据脱敏</title>
      <link>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/orchestration/encrypt/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/features/orchestration/encrypt/</guid>
      <description>一、背景
安全控制一直是治理的重要环节，数据脱敏属于安全控制的范畴。对互联网公司、传统行业来说，数据安全一直是极为重视和敏感的话题。数据脱敏是指对某些敏感信息通过脱敏规则进行数据的变形，实现敏感隐私数据的可靠保护。涉及客户安全数据或者一些商业性敏感数据，如身份证号、手机号、卡号、客户号等个人信息按照相关部门规定，都需要进行数据脱敏。
在真实业务场景中，相关业务开发团队则往往需要针对公司安全部门需求，自行实行并维护一套加解密系统，而当脱敏场景发生改变时，自行维护的脱敏系统往往又面临着重构或修改风险。此外，对于已经上线的业务，如何在不修改业务逻辑、业务SQL的情况下，透明化、安全低风险地实现无缝进行脱敏改造呢？
Apache ShardingSphere根据业界对脱敏的需求及业务改造痛点，提供了一套完整、安全、透明化、低改造成本的数据脱敏整合解决方案。
二、前序
Apache ShardingSphere是一套开源的分布式数据库中间件解决方案组成的生态圈，它由Sharding-JDBC、Sharding-Proxy和Sharding-Sidecar（规划中）这3款相互独立，却又能够混合部署配合使用的产品组成。它们均能够提供标准化的数据分片、分布式事务和分布式治理功能，可适用于如Java同构、异构语言、容器、云原生等各种多样化的应用场景。
数据脱敏模块属于ShardingSphere分布式治理这一核心功能下的子功能模块。它通过对用户输入的SQL进行解析，并依据用户提供的脱敏配置对SQL进行改写，从而实现对原文数据进行加密，并将原文数据(可选)及密文数据同时存储到底层数据库。在用户查询数据时，它又从数据库中取出密文数据，并对其解密，最终将解密后的原始数据返回给用户。Apache ShardingSphere分布式数据库中间件自动化&amp;amp;透明化了数据脱敏过程，让用户无需关注数据脱敏的实现细节，像使用普通数据那样使用脱敏数据。此外，无论是已在线业务进行脱敏改造，还是新上线业务使用脱敏功能，ShardingSphere都可以提供一套相对完善的解决方案。
三、需求场景分析
对于数据脱敏的需求，在现实的业务场景中一般分为两种情况：
 新业务上线，安全部门规定需将涉及用户敏感信息，例如银行、手机号码等进行加密后存储到数据库，在使用的时候再进行解密处理。因为是全新系统，因而没有存量数据清洗问题，所以实现相对简单。
 已上线业务，之前一直将明文存储在数据库中。相关部门突然需要对已上线业务进行脱敏整改。这种场景一般需要处理三个问题：
  a) 历史数据需要如何进行脱敏处理，即洗数。
b) 如何能在不改动业务SQL和逻辑情况下，将新增数据进行脱敏处理，并存储到数据库；在使用时，再进行解密取出。
c) 如何较为安全、无缝、透明化地实现业务系统在明文与密文数据间的迁移。
四、处理流程详解
整体架构 ShardingSphere提供的Encrypt-JDBC和业务代码部署在一起。业务方需面向Encrypt-JDBC进行JDBC编程。由于Encrypt-JDBC实现所有JDBC标准接口，业务代码无需做额外改造即可兼容使用。此时，业务代码所有与数据库的交互行为交由Encrypt-JDBC负责。业务只需提供脱敏规则即可。作为业务代码与底层数据库中间的桥梁，Encrypt-JDBC便可拦截用户行为，并在改造行为后与数据库交互。
Encrypt-JDBC将用户发起的SQL进行拦截，并通过SQL语法解析器进行解析、理解SQL行为，再依据用户传入的脱敏规则，找出需要脱敏的字段和所使用的加解密器对目标字段进行加解密处理后，再与底层数据库进行交互。ShardingSphere会将用户请求的明文进行加密后存储到底层数据库；并在用户查询时，将密文从数据库中取出进行解密后返回给终端用户。ShardingSphere通过屏蔽对数据的脱敏处理，使用户无需感知解析SQL、数据加密、数据解密的处理过程，就像在使用普通数据一样使用脱敏数据。
脱敏规则 在详解整套流程之前，我们需要先了解下脱敏规则与配置，这是认识整套流程的基础。脱敏配置主要分为四部分：数据源配置，加密器配置，脱敏表配置以及查询属性配置，其详情如下图所示：
数据源配置：是指DataSource的配置。
加密器配置：是指使用什么加密策略进行加解密。目前ShardingSphere内置了两种加解密策略：AES/MD5。用户还可以通过实现ShardingSphere提供的接口，自行实现一套加解密算法。
脱敏表配置：用于告诉ShardingSphere数据表里哪个列用于存储密文数据（cipherColumn）、哪个列用于存储明文数据（plainColumn）以及用户想使用哪个列进行SQL编写（logicColumn）。
 如何理解用户想使用哪个列进行SQL编写（logicColumn）？
我们可以从Encrypt-JDBC存在的意义来理解。Encrypt-JDBC最终目的是希望屏蔽底层对数据的脱敏处理，也就是说我们不希望用户知道数据是如何被加解密的、如何将明文数据存储到plainColumn，将密文数据存储到cipherColumn。换句话说，我们不希望用户知道plainColumn和cipherColumn的存在和使用。所以，我们需要给用户提供一个概念意义上的列，这个列可以脱离底层数据库的真实列，它可以是数据库表里的一个真实列，也可以不是，从而使得用户可以随意改变底层数据库的plainColumn和cipherColumn的列名。或者删除plainColumn，选择永远不再存储明文，只存储密文。只要用户的SQL面向这个逻辑列进行编写，并在脱敏规则里给出logicColumn和plainColumn、cipherColumn之间正确的映射关系即可。
为什么要这么做呢？答案在文章后面，即为了让已上线的业务能无缝、透明、安全地进行数据脱敏迁移。
 查询属性的配置：当底层数据库表里同时存储了明文数据、密文数据后，该属性开关用于决定是直接查询数据库表里的明文数据进行返回，还是查询密文数据通过Encrypt-JDBC解密后返回。
脱敏处理过程 举个栗子，假如数据库里有一张表叫做t_user，这张表里实际有两个字段pwd_plain，用于存放明文数据、pwd_cipher，用于存放密文数据，同时定义logicColumn为pwd。那么，用户在编写SQL时应该面向logicColumn进行编写，即INSERT INTO t_user SET pwd = &amp;lsquo;123&amp;rsquo;。ShardingSphere接收到该SQL，通过用户提供的脱敏配置，发现pwd是logicColumn，于是便对逻辑列及其对应的明文数据进行脱敏处理。可以看出ShardingSphere将面向用户的逻辑列与面向底层数据库的明文列和密文列进行了列名以及数据的脱敏映射转换。如下图所示：
这也正是Encrypt-JDBC核心意义所在，即依据用户提供的脱敏规则，将用户SQL与底层数据表结构割裂开来，使得用户的SQL编写不再依赖于真实的数据库表结构。而用户与底层数据库之间的衔接、映射、转换交由ShardingSphere进行处理。为什么我们要这么做？还是那句话：为了让已上线的业务能无缝、透明、安全地进行数据脱敏迁移。
为了让读者更清晰了解到Encrypt-JDBC的核心处理流程，下方图片展示了使用Encrypt-JDBC进行增删改查时，其中的处理流程和转换逻辑，如下图所示。
五、解决方案详解
在了解了ShardingSphere脱敏处理流程后，即可将脱敏配置、脱敏处理流程与实际场景进行结合。所有的设计开发都是为了解决业务场景遇到的痛点。那么面对之前提到的业务场景需求，又应该如何使用ShardingSphere这把利器来满足业务需求呢？
新上线业务 业务场景分析：新上线业务由于一切从零开始，不存在历史数据清洗问题，所以相对简单。
解决方案说明：选择合适的加密器，如AES后，只需配置逻辑列（面向用户编写SQL）和密文列（数据表存密文数据）即可，逻辑列和密文列可以相同也可以不同。建议配置如下（Yaml格式展示）：
encryptRule: encryptors: aes_encryptor: type: aes props: aes.key.value: 123456abc tables: t_user: columns: pwd: cipherColumn: pwd encryptor: aes_encryptor  使用这套配置，Encrypt-JDBC只需将logicColumn和cipherColumn进行转换，底层数据表不存储明文，只存储了密文，这也是安全审计部分的要求所在。如果用户希望将明文、密文一同存储到数据库，只需添加plainColumn配置即可。整体处理流程如下图所示：</description>
    </item>
    
    <item>
      <title>数据脱敏</title>
      <link>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/manual/sharding-jdbc/usage/encrypt/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shardingsphere.apache.org/document/legacy/4.x/document/cn/manual/sharding-jdbc/usage/encrypt/</guid>
      <description>该章节主要介绍如何使用数据脱敏功能，如何进行相关配置。数据脱敏功能即可与数据分片功能共同使用，又可作为单独功能组件，独立使用。 与数据分片功能共同使用时，会创建ShardingDataSource；单独使用时，会创建EncryptDataSource来完成数据脱敏功能。
不使用Spring 引入Maven依赖 &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.apache.shardingsphere&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;sharding-jdbc-core&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;${sharding-sphere.version}&amp;lt;/version&amp;gt; &amp;lt;/dependency&amp;gt;  基于Java编码的规则配置 // 配置数据源 BasicDataSource dataSource = new BasicDataSource(); dataSource.setDriverClassName(&amp;quot;com.mysql.jdbc.Driver&amp;quot;); dataSource.setUrl(&amp;quot;jdbc:mysql://127.0.0.1:3306/encrypt&amp;quot;); dataSource.setUsername(&amp;quot;root&amp;quot;); dataSource.setPassword(&amp;quot;&amp;quot;); // 配置脱敏规则 Properties props = new Properties(); props.setProperty(&amp;quot;aes.key.value&amp;quot;, &amp;quot;123456&amp;quot;); EncryptorRuleConfiguration encryptorConfig = new EncryptorRuleConfiguration(&amp;quot;AES&amp;quot;, props); EncryptColumnRuleConfiguration columnConfig = new EncryptColumnRuleConfiguration(&amp;quot;plain_pwd&amp;quot;, &amp;quot;cipher_pwd&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;aes&amp;quot;); EncryptTableRuleConfiguration tableConfig = new EncryptTableRuleConfiguration(Collections.singletonMap(&amp;quot;pwd&amp;quot;, columnConfig)); EncryptRuleConfiguration encryptRuleConfig = new EncryptRuleConfiguration(); encryptRuleConfig.getEncryptors().put(&amp;quot;aes&amp;quot;, encryptorConfig); encryptRuleConfig.getTables().put(&amp;quot;t_encrypt&amp;quot;, tableConfig); // 获取数据源对象 DataSource dataSource = EncryptDataSourceFactory.createDataSource(dataSource, encryptRuleConfig, new Properties());  基于Yaml的规则配置 或通过Yaml方式配置，与以上配置等价：</description>
    </item>
    
  </channel>
</rss>